{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IoT Aides Project (Wingbeat Audio Classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Developed by: Husnul Amri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Creating Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Code adapted from: https://medium.com/@sdoshi579/classification-of-music-into-different-genres-using-keras-82ab5339efe0\n",
    "#with some modification to work on this project\n",
    "\n",
    "#importing important library\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import csv\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, LabelBinarizer\n",
    "\n",
    "#Keras\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Header for the CSV file on each features\n",
    "# header = 'filename chroma_stft rmse spectral_centroid spectral_bandwidth rolloff zero_crossing_rate'\n",
    "header = 'filename'\n",
    "for i in range(1, 14):\n",
    "    header += f' mfcc{i}'\n",
    "for i in range(1,14):\n",
    "    header += f' mfcc_delta{i}'\n",
    "for i in range(1,14):\n",
    "    header += f' mfcc_delta^2_{i}'\n",
    "header += ' label'\n",
    "header = header.split()\n",
    "\n",
    "#defining the dataset label based on the name\n",
    "def label_wav(filename):\n",
    "    word_label = filename.split('_')[0]\n",
    "    if word_label == 'aegyptibetina': return 'aegypti'\n",
    "    if word_label == 'aegypti': return 'aegypti'\n",
    "    if word_label == 'albopictus': return 'others'\n",
    "    if word_label == 'aegyptijantan': return 'others'\n",
    "    if word_label == 'albojantan': return 'others'\n",
    "    elif word_label == 'AlboBetina': return 'others'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moezeus/anaconda3/lib/python3.7/site-packages/librosa/core/audio.py:161: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/moezeus/anaconda3/lib/python3.7/site-packages/librosa/core/audio.py:161: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/moezeus/anaconda3/lib/python3.7/site-packages/librosa/core/audio.py:161: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/moezeus/anaconda3/lib/python3.7/site-packages/librosa/core/audio.py:161: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/moezeus/anaconda3/lib/python3.7/site-packages/librosa/core/audio.py:161: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n",
      "/home/moezeus/anaconda3/lib/python3.7/site-packages/librosa/core/audio.py:161: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n"
     ]
    }
   ],
   "source": [
    "#Creating CSV file with audio feature extraction\n",
    "file = open('data_final.csv', 'w', newline='')\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(header)\n",
    "for filename in os.listdir(f'./rekaman_nyamuk/'):\n",
    "    songname = f'./rekaman_nyamuk/{filename}'\n",
    "    labels = label_wav(filename)\n",
    "    y, sr = librosa.load(songname, mono=True, duration=25)\n",
    "#     chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "#     rmse = librosa.feature.rms(y=y)\n",
    "#     spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "#     spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "#     rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "#     zcr = librosa.feature.zero_crossing_rate(y)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13,fmin=400, fmax=10000)\n",
    "#     mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "    mfcc_delta = librosa.feature.delta(mfcc)\n",
    "    mfcc_delta2 = librosa.feature.delta(mfcc,order=2)\n",
    "#     to_append = f'{filename} {np.mean(chroma_stft)} {np.mean(rmse)} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(rolloff)} {np.mean(zcr)}'    \n",
    "    to_append = f'{filename}'\n",
    "    for e in mfcc:\n",
    "        to_append += f' {np.mean(e)}'\n",
    "    for e in mfcc_delta:\n",
    "        to_append += f' {np.mean(e)}'\n",
    "    for e in mfcc_delta2:\n",
    "        to_append += f' {np.mean(e)}'\n",
    "    to_append += f' {labels}'\n",
    "    file = open('data_final.csv', 'a', newline='')\n",
    "    with file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(to_append.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the CSV file to dataframe\n",
    "data = pd.read_csv('data_final.csv')\n",
    "# data = data.reindex(np.random.permutation(data.index)) \n",
    "# Dropping unneccesary columns\n",
    "data = data.drop(['filename'],axis=1)\n",
    "#encode the mosquito name to binary\n",
    "mosq_list = data.iloc[:, -1]\n",
    "encoder = LabelBinarizer()\n",
    "y = encoder.fit_transform(mosq_list)\n",
    "#convert the encode result to 2D array format\n",
    "yr = np.array([[item[0], 0 if item[0] else 1] for item in y])\n",
    "#insert the other row to X\n",
    "X = np.array(data.iloc[:, :-1])\n",
    "# X = MinMaxScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating data train and test for validation and training process\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, yr, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining classification model (Learning)\n",
    "from keras import models\n",
    "from keras import layers\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(32, activation='relu', input_dim=39))\n",
    "# model.add(layers.Dense(128, activation='relu'))\n",
    "# model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 202 samples, validate on 51 samples\n",
      "Epoch 1/1000\n",
      "202/202 [==============================] - 0s 895us/step - loss: 3.7043 - accuracy: 0.6881 - val_loss: 2.4364 - val_accuracy: 0.6275\n",
      "Epoch 2/1000\n",
      "202/202 [==============================] - 0s 84us/step - loss: 1.7480 - accuracy: 0.6881 - val_loss: 1.3891 - val_accuracy: 0.4118\n",
      "Epoch 3/1000\n",
      "202/202 [==============================] - 0s 111us/step - loss: 1.2485 - accuracy: 0.5149 - val_loss: 1.8882 - val_accuracy: 0.5686\n",
      "Epoch 4/1000\n",
      "202/202 [==============================] - 0s 151us/step - loss: 0.9726 - accuracy: 0.6386 - val_loss: 1.1405 - val_accuracy: 0.5490\n",
      "Epoch 5/1000\n",
      "202/202 [==============================] - 0s 95us/step - loss: 0.8311 - accuracy: 0.6535 - val_loss: 1.0605 - val_accuracy: 0.5882\n",
      "Epoch 6/1000\n",
      "202/202 [==============================] - 0s 128us/step - loss: 0.6742 - accuracy: 0.6832 - val_loss: 1.0291 - val_accuracy: 0.5490\n",
      "Epoch 7/1000\n",
      "202/202 [==============================] - 0s 179us/step - loss: 0.5901 - accuracy: 0.6931 - val_loss: 0.8118 - val_accuracy: 0.6275\n",
      "Epoch 8/1000\n",
      "202/202 [==============================] - 0s 145us/step - loss: 0.5399 - accuracy: 0.7228 - val_loss: 0.7653 - val_accuracy: 0.5490\n",
      "Epoch 9/1000\n",
      "202/202 [==============================] - 0s 152us/step - loss: 0.4588 - accuracy: 0.7723 - val_loss: 0.9800 - val_accuracy: 0.6471\n",
      "Epoch 10/1000\n",
      "202/202 [==============================] - 0s 103us/step - loss: 0.4976 - accuracy: 0.7772 - val_loss: 0.8298 - val_accuracy: 0.6667\n",
      "Epoch 11/1000\n",
      "202/202 [==============================] - 0s 81us/step - loss: 0.5278 - accuracy: 0.7525 - val_loss: 0.6612 - val_accuracy: 0.6863\n",
      "Epoch 12/1000\n",
      "202/202 [==============================] - 0s 131us/step - loss: 0.4391 - accuracy: 0.8020 - val_loss: 0.5842 - val_accuracy: 0.6667\n",
      "Epoch 13/1000\n",
      "202/202 [==============================] - 0s 80us/step - loss: 0.4781 - accuracy: 0.7871 - val_loss: 0.6852 - val_accuracy: 0.7255\n",
      "Epoch 14/1000\n",
      "202/202 [==============================] - 0s 165us/step - loss: 0.3522 - accuracy: 0.8366 - val_loss: 0.5308 - val_accuracy: 0.7255\n",
      "Epoch 15/1000\n",
      "202/202 [==============================] - 0s 128us/step - loss: 0.3437 - accuracy: 0.8416 - val_loss: 0.4948 - val_accuracy: 0.6863\n",
      "Epoch 16/1000\n",
      "202/202 [==============================] - 0s 117us/step - loss: 0.3448 - accuracy: 0.8267 - val_loss: 0.5762 - val_accuracy: 0.7843\n",
      "Epoch 17/1000\n",
      "202/202 [==============================] - 0s 151us/step - loss: 0.3061 - accuracy: 0.8911 - val_loss: 0.5991 - val_accuracy: 0.8039\n",
      "Epoch 18/1000\n",
      "202/202 [==============================] - 0s 131us/step - loss: 0.2845 - accuracy: 0.9059 - val_loss: 0.4412 - val_accuracy: 0.7451\n",
      "Epoch 19/1000\n",
      "202/202 [==============================] - 0s 96us/step - loss: 0.3085 - accuracy: 0.8713 - val_loss: 0.4755 - val_accuracy: 0.7647\n",
      "Epoch 20/1000\n",
      "202/202 [==============================] - 0s 131us/step - loss: 0.2825 - accuracy: 0.8713 - val_loss: 0.5959 - val_accuracy: 0.8039\n",
      "Epoch 21/1000\n",
      "202/202 [==============================] - 0s 101us/step - loss: 0.2807 - accuracy: 0.8812 - val_loss: 0.7024 - val_accuracy: 0.7451\n",
      "Epoch 22/1000\n",
      "202/202 [==============================] - 0s 126us/step - loss: 0.3411 - accuracy: 0.8614 - val_loss: 0.5034 - val_accuracy: 0.8039\n",
      "Epoch 23/1000\n",
      "202/202 [==============================] - 0s 86us/step - loss: 0.3212 - accuracy: 0.8465 - val_loss: 0.4386 - val_accuracy: 0.7451\n",
      "Epoch 24/1000\n",
      "202/202 [==============================] - 0s 107us/step - loss: 0.2591 - accuracy: 0.8960 - val_loss: 0.4172 - val_accuracy: 0.7843\n",
      "Epoch 25/1000\n",
      "202/202 [==============================] - 0s 118us/step - loss: 0.3403 - accuracy: 0.8465 - val_loss: 0.6908 - val_accuracy: 0.7255\n",
      "Epoch 26/1000\n",
      "202/202 [==============================] - 0s 129us/step - loss: 0.2396 - accuracy: 0.8911 - val_loss: 0.4801 - val_accuracy: 0.7843\n",
      "Epoch 27/1000\n",
      "202/202 [==============================] - 0s 101us/step - loss: 0.2754 - accuracy: 0.9010 - val_loss: 0.3727 - val_accuracy: 0.8039\n",
      "Epoch 28/1000\n",
      "202/202 [==============================] - 0s 117us/step - loss: 0.3317 - accuracy: 0.8515 - val_loss: 0.5938 - val_accuracy: 0.7843\n",
      "Epoch 29/1000\n",
      "202/202 [==============================] - 0s 107us/step - loss: 0.3251 - accuracy: 0.8614 - val_loss: 0.7736 - val_accuracy: 0.7059\n",
      "Epoch 30/1000\n",
      "202/202 [==============================] - 0s 91us/step - loss: 0.2989 - accuracy: 0.8465 - val_loss: 0.4294 - val_accuracy: 0.7451\n",
      "Epoch 31/1000\n",
      "202/202 [==============================] - 0s 148us/step - loss: 0.3153 - accuracy: 0.8465 - val_loss: 0.4372 - val_accuracy: 0.7843\n",
      "Epoch 32/1000\n",
      "202/202 [==============================] - 0s 94us/step - loss: 0.3533 - accuracy: 0.8416 - val_loss: 0.7811 - val_accuracy: 0.7059\n",
      "Epoch 33/1000\n",
      "202/202 [==============================] - 0s 172us/step - loss: 0.2760 - accuracy: 0.8812 - val_loss: 0.4061 - val_accuracy: 0.8235\n",
      "Epoch 34/1000\n",
      "202/202 [==============================] - 0s 106us/step - loss: 0.2231 - accuracy: 0.9208 - val_loss: 0.3609 - val_accuracy: 0.8431\n",
      "Epoch 35/1000\n",
      "202/202 [==============================] - 0s 124us/step - loss: 0.2215 - accuracy: 0.9059 - val_loss: 0.3977 - val_accuracy: 0.8824\n",
      "Epoch 36/1000\n",
      "202/202 [==============================] - 0s 119us/step - loss: 0.1839 - accuracy: 0.9208 - val_loss: 0.5253 - val_accuracy: 0.8039\n",
      "Epoch 37/1000\n",
      "202/202 [==============================] - 0s 134us/step - loss: 0.1900 - accuracy: 0.9455 - val_loss: 0.4106 - val_accuracy: 0.8824\n",
      "Epoch 38/1000\n",
      "202/202 [==============================] - 0s 89us/step - loss: 0.1759 - accuracy: 0.9703 - val_loss: 0.4003 - val_accuracy: 0.8627\n",
      "Epoch 39/1000\n",
      "202/202 [==============================] - 0s 108us/step - loss: 0.1634 - accuracy: 0.9703 - val_loss: 0.3818 - val_accuracy: 0.8824\n",
      "Epoch 40/1000\n",
      "202/202 [==============================] - 0s 91us/step - loss: 0.1606 - accuracy: 0.9554 - val_loss: 0.4253 - val_accuracy: 0.8235\n",
      "Epoch 41/1000\n",
      "202/202 [==============================] - 0s 116us/step - loss: 0.1317 - accuracy: 0.9505 - val_loss: 0.3303 - val_accuracy: 0.8627\n",
      "Epoch 42/1000\n",
      "202/202 [==============================] - 0s 130us/step - loss: 0.1599 - accuracy: 0.9406 - val_loss: 0.4132 - val_accuracy: 0.8824\n",
      "Epoch 43/1000\n",
      "202/202 [==============================] - 0s 93us/step - loss: 0.1145 - accuracy: 0.9653 - val_loss: 0.3158 - val_accuracy: 0.8824\n",
      "Epoch 44/1000\n",
      "202/202 [==============================] - 0s 136us/step - loss: 0.1102 - accuracy: 0.9653 - val_loss: 0.3580 - val_accuracy: 0.8824\n",
      "Epoch 45/1000\n",
      "202/202 [==============================] - 0s 120us/step - loss: 0.1085 - accuracy: 0.9703 - val_loss: 0.2922 - val_accuracy: 0.8627\n",
      "Epoch 46/1000\n",
      "202/202 [==============================] - 0s 146us/step - loss: 0.1954 - accuracy: 0.9059 - val_loss: 0.6062 - val_accuracy: 0.7843\n",
      "Epoch 47/1000\n",
      "202/202 [==============================] - 0s 123us/step - loss: 0.1583 - accuracy: 0.9257 - val_loss: 0.3956 - val_accuracy: 0.8431\n",
      "Epoch 48/1000\n",
      "202/202 [==============================] - 0s 98us/step - loss: 0.1731 - accuracy: 0.9406 - val_loss: 0.2800 - val_accuracy: 0.8824\n",
      "Epoch 49/1000\n",
      "202/202 [==============================] - 0s 107us/step - loss: 0.1549 - accuracy: 0.9406 - val_loss: 0.4622 - val_accuracy: 0.8431\n",
      "Epoch 50/1000\n",
      "202/202 [==============================] - 0s 101us/step - loss: 0.1288 - accuracy: 0.9505 - val_loss: 0.3011 - val_accuracy: 0.8824\n",
      "Epoch 51/1000\n",
      "202/202 [==============================] - 0s 109us/step - loss: 0.1046 - accuracy: 0.9554 - val_loss: 0.4562 - val_accuracy: 0.8431\n",
      "Epoch 52/1000\n",
      "202/202 [==============================] - 0s 152us/step - loss: 0.0950 - accuracy: 0.9802 - val_loss: 0.2358 - val_accuracy: 0.9020\n",
      "Epoch 53/1000\n",
      "202/202 [==============================] - 0s 127us/step - loss: 0.1046 - accuracy: 0.9752 - val_loss: 0.2931 - val_accuracy: 0.8824\n",
      "Epoch 54/1000\n",
      "202/202 [==============================] - 0s 119us/step - loss: 0.0840 - accuracy: 0.9653 - val_loss: 0.2660 - val_accuracy: 0.9216\n",
      "Epoch 55/1000\n",
      "202/202 [==============================] - 0s 113us/step - loss: 0.0808 - accuracy: 0.9752 - val_loss: 0.3028 - val_accuracy: 0.8824\n",
      "Epoch 56/1000\n",
      "202/202 [==============================] - 0s 151us/step - loss: 0.0805 - accuracy: 0.9802 - val_loss: 0.2606 - val_accuracy: 0.9216\n",
      "Epoch 57/1000\n",
      "202/202 [==============================] - 0s 126us/step - loss: 0.0758 - accuracy: 0.9752 - val_loss: 0.2792 - val_accuracy: 0.9020\n",
      "Epoch 58/1000\n",
      "202/202 [==============================] - 0s 109us/step - loss: 0.0741 - accuracy: 0.9703 - val_loss: 0.2431 - val_accuracy: 0.9216\n",
      "Epoch 59/1000\n",
      "202/202 [==============================] - 0s 86us/step - loss: 0.0810 - accuracy: 0.9703 - val_loss: 0.2759 - val_accuracy: 0.9020\n",
      "Epoch 60/1000\n",
      "202/202 [==============================] - 0s 80us/step - loss: 0.0751 - accuracy: 0.9752 - val_loss: 0.2378 - val_accuracy: 0.9216\n",
      "Epoch 61/1000\n",
      "202/202 [==============================] - 0s 86us/step - loss: 0.0874 - accuracy: 0.9604 - val_loss: 0.3021 - val_accuracy: 0.8824\n",
      "Epoch 62/1000\n",
      "202/202 [==============================] - 0s 85us/step - loss: 0.0696 - accuracy: 0.9653 - val_loss: 0.2785 - val_accuracy: 0.9216\n",
      "Epoch 63/1000\n",
      "202/202 [==============================] - 0s 85us/step - loss: 0.1000 - accuracy: 0.9802 - val_loss: 0.2207 - val_accuracy: 0.9412\n",
      "Epoch 64/1000\n",
      "202/202 [==============================] - 0s 84us/step - loss: 0.0927 - accuracy: 0.9604 - val_loss: 0.4705 - val_accuracy: 0.8627\n",
      "Epoch 65/1000\n",
      "202/202 [==============================] - 0s 86us/step - loss: 0.0855 - accuracy: 0.9752 - val_loss: 0.2027 - val_accuracy: 0.9412\n",
      "Epoch 66/1000\n",
      "202/202 [==============================] - 0s 89us/step - loss: 0.0685 - accuracy: 0.9703 - val_loss: 0.2957 - val_accuracy: 0.9020\n",
      "Epoch 67/1000\n",
      "202/202 [==============================] - 0s 83us/step - loss: 0.0748 - accuracy: 0.9752 - val_loss: 0.2361 - val_accuracy: 0.9412\n",
      "Epoch 68/1000\n",
      "202/202 [==============================] - 0s 85us/step - loss: 0.0687 - accuracy: 0.9802 - val_loss: 0.2302 - val_accuracy: 0.9412\n",
      "Epoch 69/1000\n",
      "202/202 [==============================] - 0s 90us/step - loss: 0.0620 - accuracy: 0.9752 - val_loss: 0.2774 - val_accuracy: 0.9216\n",
      "Epoch 70/1000\n",
      "202/202 [==============================] - 0s 89us/step - loss: 0.0594 - accuracy: 0.9851 - val_loss: 0.2437 - val_accuracy: 0.9216\n",
      "Epoch 71/1000\n",
      "202/202 [==============================] - 0s 90us/step - loss: 0.0641 - accuracy: 0.9851 - val_loss: 0.1926 - val_accuracy: 0.9412\n",
      "Epoch 72/1000\n",
      "202/202 [==============================] - 0s 88us/step - loss: 0.0607 - accuracy: 0.9752 - val_loss: 0.3421 - val_accuracy: 0.8627\n",
      "Epoch 73/1000\n",
      "202/202 [==============================] - 0s 101us/step - loss: 0.1499 - accuracy: 0.9505 - val_loss: 0.3006 - val_accuracy: 0.8824\n",
      "Epoch 74/1000\n",
      "202/202 [==============================] - 0s 86us/step - loss: 0.1324 - accuracy: 0.9406 - val_loss: 0.4058 - val_accuracy: 0.9020\n",
      "Epoch 75/1000\n",
      "202/202 [==============================] - 0s 86us/step - loss: 0.1014 - accuracy: 0.9455 - val_loss: 0.1885 - val_accuracy: 0.9412\n",
      "Epoch 76/1000\n",
      "202/202 [==============================] - 0s 89us/step - loss: 0.0607 - accuracy: 0.9851 - val_loss: 0.3450 - val_accuracy: 0.8627\n",
      "Epoch 77/1000\n",
      "202/202 [==============================] - 0s 97us/step - loss: 0.0627 - accuracy: 0.9802 - val_loss: 0.1705 - val_accuracy: 0.9412\n",
      "Epoch 78/1000\n",
      "202/202 [==============================] - 0s 93us/step - loss: 0.0498 - accuracy: 0.9752 - val_loss: 0.2154 - val_accuracy: 0.9412\n",
      "Epoch 79/1000\n",
      "202/202 [==============================] - 0s 87us/step - loss: 0.0472 - accuracy: 0.9851 - val_loss: 0.2063 - val_accuracy: 0.9608\n",
      "Epoch 80/1000\n",
      "202/202 [==============================] - 0s 102us/step - loss: 0.0452 - accuracy: 0.9901 - val_loss: 0.2047 - val_accuracy: 0.9608\n",
      "Epoch 81/1000\n",
      "202/202 [==============================] - 0s 95us/step - loss: 0.0409 - accuracy: 0.9901 - val_loss: 0.1986 - val_accuracy: 0.9608\n",
      "Epoch 82/1000\n",
      "202/202 [==============================] - 0s 91us/step - loss: 0.0412 - accuracy: 0.9901 - val_loss: 0.2213 - val_accuracy: 0.9608\n",
      "Epoch 83/1000\n",
      "202/202 [==============================] - 0s 84us/step - loss: 0.0390 - accuracy: 0.9901 - val_loss: 0.1858 - val_accuracy: 0.9608\n",
      "Epoch 84/1000\n",
      "202/202 [==============================] - 0s 90us/step - loss: 0.0373 - accuracy: 0.9901 - val_loss: 0.2201 - val_accuracy: 0.9608\n",
      "Epoch 85/1000\n",
      "202/202 [==============================] - 0s 88us/step - loss: 0.0392 - accuracy: 0.9901 - val_loss: 0.2095 - val_accuracy: 0.9608\n",
      "Epoch 86/1000\n",
      "202/202 [==============================] - 0s 87us/step - loss: 0.0362 - accuracy: 0.9901 - val_loss: 0.1899 - val_accuracy: 0.9608\n",
      "Epoch 87/1000\n",
      "202/202 [==============================] - 0s 95us/step - loss: 0.0354 - accuracy: 0.9901 - val_loss: 0.1773 - val_accuracy: 0.9608\n",
      "Epoch 88/1000\n",
      "202/202 [==============================] - 0s 104us/step - loss: 0.0361 - accuracy: 0.9901 - val_loss: 0.2219 - val_accuracy: 0.9412\n",
      "Epoch 89/1000\n",
      "202/202 [==============================] - 0s 99us/step - loss: 0.0418 - accuracy: 0.9851 - val_loss: 0.1665 - val_accuracy: 0.9608\n",
      "Epoch 90/1000\n",
      "202/202 [==============================] - 0s 92us/step - loss: 0.0407 - accuracy: 0.9901 - val_loss: 0.2146 - val_accuracy: 0.9412\n",
      "Epoch 91/1000\n",
      "202/202 [==============================] - 0s 93us/step - loss: 0.0497 - accuracy: 0.9851 - val_loss: 0.1891 - val_accuracy: 0.9608\n",
      "Epoch 92/1000\n",
      "202/202 [==============================] - 0s 98us/step - loss: 0.0386 - accuracy: 0.9901 - val_loss: 0.1565 - val_accuracy: 0.9804\n",
      "Epoch 93/1000\n",
      "202/202 [==============================] - 0s 86us/step - loss: 0.0416 - accuracy: 0.9802 - val_loss: 0.2127 - val_accuracy: 0.9412\n",
      "Epoch 94/1000\n",
      "202/202 [==============================] - 0s 101us/step - loss: 0.0361 - accuracy: 0.9851 - val_loss: 0.1718 - val_accuracy: 0.9608\n",
      "Epoch 95/1000\n",
      "202/202 [==============================] - 0s 91us/step - loss: 0.0413 - accuracy: 0.9901 - val_loss: 0.2014 - val_accuracy: 0.9608\n",
      "Epoch 96/1000\n",
      "202/202 [==============================] - 0s 92us/step - loss: 0.0321 - accuracy: 0.9901 - val_loss: 0.1664 - val_accuracy: 0.9608\n",
      "Epoch 97/1000\n",
      "202/202 [==============================] - 0s 89us/step - loss: 0.0332 - accuracy: 0.9901 - val_loss: 0.2194 - val_accuracy: 0.9608\n",
      "Epoch 98/1000\n",
      "202/202 [==============================] - 0s 91us/step - loss: 0.0382 - accuracy: 0.9901 - val_loss: 0.1801 - val_accuracy: 0.9608\n",
      "Epoch 99/1000\n",
      "202/202 [==============================] - 0s 81us/step - loss: 0.0287 - accuracy: 0.9901 - val_loss: 0.2041 - val_accuracy: 0.9608\n",
      "Epoch 100/1000\n",
      "202/202 [==============================] - 0s 86us/step - loss: 0.0322 - accuracy: 0.9901 - val_loss: 0.1525 - val_accuracy: 0.9804\n",
      "Epoch 101/1000\n",
      "202/202 [==============================] - 0s 89us/step - loss: 0.0292 - accuracy: 1.0000 - val_loss: 0.1984 - val_accuracy: 0.9608\n",
      "Epoch 102/1000\n",
      "202/202 [==============================] - 0s 94us/step - loss: 0.0293 - accuracy: 0.9901 - val_loss: 0.1868 - val_accuracy: 0.9608\n",
      "Epoch 103/1000\n",
      "202/202 [==============================] - 0s 90us/step - loss: 0.0250 - accuracy: 0.9901 - val_loss: 0.1628 - val_accuracy: 0.9608\n",
      "Epoch 104/1000\n",
      "202/202 [==============================] - 0s 86us/step - loss: 0.0275 - accuracy: 0.9950 - val_loss: 0.1615 - val_accuracy: 0.9608\n",
      "Epoch 105/1000\n",
      "202/202 [==============================] - 0s 94us/step - loss: 0.0259 - accuracy: 0.9950 - val_loss: 0.1757 - val_accuracy: 0.9608\n",
      "Epoch 106/1000\n",
      "202/202 [==============================] - 0s 96us/step - loss: 0.0267 - accuracy: 0.9901 - val_loss: 0.1708 - val_accuracy: 0.9608\n",
      "Epoch 107/1000\n",
      "202/202 [==============================] - 0s 71us/step - loss: 0.0251 - accuracy: 1.0000 - val_loss: 0.1343 - val_accuracy: 0.9804\n",
      "Epoch 108/1000\n",
      "202/202 [==============================] - 0s 93us/step - loss: 0.0253 - accuracy: 1.0000 - val_loss: 0.1938 - val_accuracy: 0.9608\n",
      "Epoch 109/1000\n",
      "202/202 [==============================] - 0s 88us/step - loss: 0.0247 - accuracy: 0.9901 - val_loss: 0.1736 - val_accuracy: 0.9608\n",
      "Epoch 110/1000\n",
      "202/202 [==============================] - 0s 111us/step - loss: 0.0232 - accuracy: 0.9901 - val_loss: 0.1735 - val_accuracy: 0.9608\n",
      "Epoch 111/1000\n",
      "202/202 [==============================] - 0s 93us/step - loss: 0.0244 - accuracy: 0.9950 - val_loss: 0.1835 - val_accuracy: 0.9608\n",
      "Epoch 112/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202/202 [==============================] - 0s 91us/step - loss: 0.0233 - accuracy: 0.9901 - val_loss: 0.1562 - val_accuracy: 0.9804\n",
      "Epoch 113/1000\n",
      "202/202 [==============================] - 0s 89us/step - loss: 0.0230 - accuracy: 1.0000 - val_loss: 0.1819 - val_accuracy: 0.9608\n",
      "Epoch 114/1000\n",
      "202/202 [==============================] - 0s 89us/step - loss: 0.0217 - accuracy: 0.9901 - val_loss: 0.1583 - val_accuracy: 0.9804\n",
      "Epoch 115/1000\n",
      "202/202 [==============================] - 0s 87us/step - loss: 0.0233 - accuracy: 0.9901 - val_loss: 0.1526 - val_accuracy: 0.9804\n",
      "Epoch 116/1000\n",
      "202/202 [==============================] - 0s 94us/step - loss: 0.0203 - accuracy: 0.9950 - val_loss: 0.1576 - val_accuracy: 0.9804\n",
      "Epoch 117/1000\n",
      "202/202 [==============================] - 0s 81us/step - loss: 0.0206 - accuracy: 0.9901 - val_loss: 0.1463 - val_accuracy: 0.9804\n",
      "Epoch 118/1000\n",
      "202/202 [==============================] - 0s 86us/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 0.1574 - val_accuracy: 0.9804\n",
      "Epoch 119/1000\n",
      "202/202 [==============================] - 0s 78us/step - loss: 0.0229 - accuracy: 0.9901 - val_loss: 0.1583 - val_accuracy: 0.9804\n",
      "Epoch 120/1000\n",
      "202/202 [==============================] - 0s 106us/step - loss: 0.0194 - accuracy: 0.9901 - val_loss: 0.1378 - val_accuracy: 0.9804\n",
      "Epoch 121/1000\n",
      "202/202 [==============================] - 0s 87us/step - loss: 0.0212 - accuracy: 1.0000 - val_loss: 0.1843 - val_accuracy: 0.9608\n",
      "Epoch 122/1000\n",
      "202/202 [==============================] - 0s 75us/step - loss: 0.0226 - accuracy: 0.9901 - val_loss: 0.1606 - val_accuracy: 0.9804\n",
      "Epoch 123/1000\n",
      "202/202 [==============================] - 0s 89us/step - loss: 0.0283 - accuracy: 0.9950 - val_loss: 0.1631 - val_accuracy: 0.9804\n",
      "Epoch 124/1000\n",
      "202/202 [==============================] - 0s 96us/step - loss: 0.0174 - accuracy: 0.9950 - val_loss: 0.1615 - val_accuracy: 0.9804\n",
      "Epoch 125/1000\n",
      "202/202 [==============================] - 0s 82us/step - loss: 0.0173 - accuracy: 0.9950 - val_loss: 0.1466 - val_accuracy: 0.9804\n",
      "Epoch 126/1000\n",
      "202/202 [==============================] - 0s 90us/step - loss: 0.0190 - accuracy: 0.9950 - val_loss: 0.1408 - val_accuracy: 0.9804\n",
      "Epoch 127/1000\n",
      "202/202 [==============================] - 0s 85us/step - loss: 0.0229 - accuracy: 0.9901 - val_loss: 0.1634 - val_accuracy: 0.9804\n",
      "Epoch 128/1000\n",
      "202/202 [==============================] - 0s 97us/step - loss: 0.0202 - accuracy: 0.9950 - val_loss: 0.1618 - val_accuracy: 0.9804\n",
      "Epoch 129/1000\n",
      "202/202 [==============================] - 0s 91us/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.1502 - val_accuracy: 0.9804\n",
      "Epoch 130/1000\n",
      "202/202 [==============================] - 0s 87us/step - loss: 0.0224 - accuracy: 0.9950 - val_loss: 0.1645 - val_accuracy: 0.9804\n",
      "Epoch 131/1000\n",
      "202/202 [==============================] - 0s 81us/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 0.1474 - val_accuracy: 0.9804\n",
      "Epoch 132/1000\n",
      "202/202 [==============================] - 0s 89us/step - loss: 0.0234 - accuracy: 0.9901 - val_loss: 0.1598 - val_accuracy: 0.9804\n",
      "Epoch 133/1000\n",
      "202/202 [==============================] - 0s 89us/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 0.1309 - val_accuracy: 0.9804\n",
      "Epoch 134/1000\n",
      "202/202 [==============================] - 0s 92us/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.1838 - val_accuracy: 0.9608\n",
      "Epoch 135/1000\n",
      "202/202 [==============================] - 0s 86us/step - loss: 0.0158 - accuracy: 0.9950 - val_loss: 0.1402 - val_accuracy: 0.9804\n",
      "Epoch 136/1000\n",
      "202/202 [==============================] - 0s 88us/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.1550 - val_accuracy: 0.9804\n",
      "Epoch 137/1000\n",
      "202/202 [==============================] - 0s 106us/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.1357 - val_accuracy: 0.9804\n",
      "Epoch 138/1000\n",
      "202/202 [==============================] - 0s 81us/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 0.1633 - val_accuracy: 0.9804\n",
      "Epoch 139/1000\n",
      "202/202 [==============================] - 0s 77us/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.1476 - val_accuracy: 0.9804\n",
      "Epoch 140/1000\n",
      "202/202 [==============================] - 0s 74us/step - loss: 0.0211 - accuracy: 0.9901 - val_loss: 0.1525 - val_accuracy: 0.9804\n",
      "Epoch 141/1000\n",
      "202/202 [==============================] - 0s 81us/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.1654 - val_accuracy: 0.9804\n",
      "Epoch 142/1000\n",
      "202/202 [==============================] - 0s 95us/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.1379 - val_accuracy: 0.9804\n",
      "Epoch 143/1000\n",
      "202/202 [==============================] - 0s 102us/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.1527 - val_accuracy: 0.9804\n",
      "Epoch 144/1000\n",
      "202/202 [==============================] - 0s 100us/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.1382 - val_accuracy: 0.9804\n",
      "Epoch 145/1000\n",
      "202/202 [==============================] - 0s 90us/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.1643 - val_accuracy: 0.9804\n",
      "Epoch 146/1000\n",
      "202/202 [==============================] - 0s 89us/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.1413 - val_accuracy: 0.9804\n",
      "Epoch 147/1000\n",
      "202/202 [==============================] - 0s 82us/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.1433 - val_accuracy: 0.9804\n",
      "Epoch 148/1000\n",
      "202/202 [==============================] - 0s 109us/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.1532 - val_accuracy: 0.9804\n",
      "Epoch 149/1000\n",
      "202/202 [==============================] - 0s 79us/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.1459 - val_accuracy: 0.9804\n",
      "Epoch 150/1000\n",
      "202/202 [==============================] - 0s 103us/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.1331 - val_accuracy: 0.9804\n",
      "Epoch 151/1000\n",
      "202/202 [==============================] - 0s 86us/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.1485 - val_accuracy: 0.9804\n",
      "Epoch 152/1000\n",
      "202/202 [==============================] - 0s 85us/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.1474 - val_accuracy: 0.9804\n",
      "Epoch 153/1000\n",
      "202/202 [==============================] - 0s 105us/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.1382 - val_accuracy: 0.9804\n",
      "Epoch 154/1000\n",
      "202/202 [==============================] - 0s 80us/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.1489 - val_accuracy: 0.9804\n",
      "Epoch 155/1000\n",
      "202/202 [==============================] - 0s 85us/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.1420 - val_accuracy: 0.9804\n",
      "Epoch 156/1000\n",
      "202/202 [==============================] - 0s 93us/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.1427 - val_accuracy: 0.9804\n",
      "Epoch 157/1000\n",
      "202/202 [==============================] - 0s 82us/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.1326 - val_accuracy: 0.9804\n",
      "Epoch 158/1000\n",
      "202/202 [==============================] - 0s 95us/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.1386 - val_accuracy: 0.9804\n",
      "Epoch 159/1000\n",
      "202/202 [==============================] - 0s 85us/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.1339 - val_accuracy: 0.9804\n",
      "Epoch 160/1000\n",
      "202/202 [==============================] - 0s 81us/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.1519 - val_accuracy: 0.9804\n",
      "Epoch 161/1000\n",
      "202/202 [==============================] - 0s 83us/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.1258 - val_accuracy: 0.9804\n",
      "Epoch 162/1000\n",
      "202/202 [==============================] - 0s 104us/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.1533 - val_accuracy: 0.9804\n",
      "Epoch 163/1000\n",
      "202/202 [==============================] - 0s 92us/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.1344 - val_accuracy: 0.9804\n",
      "Epoch 164/1000\n",
      "202/202 [==============================] - 0s 67us/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.1306 - val_accuracy: 0.9804\n",
      "Epoch 165/1000\n",
      "202/202 [==============================] - 0s 90us/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.1455 - val_accuracy: 0.9804\n",
      "Epoch 166/1000\n",
      "202/202 [==============================] - 0s 83us/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.1351 - val_accuracy: 0.9804\n",
      "Epoch 167/1000\n",
      "202/202 [==============================] - 0s 103us/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.1393 - val_accuracy: 0.9804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168/1000\n",
      "202/202 [==============================] - 0s 104us/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.1416 - val_accuracy: 0.9804\n",
      "Epoch 169/1000\n",
      "202/202 [==============================] - 0s 104us/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.1283 - val_accuracy: 0.9804\n",
      "Epoch 170/1000\n",
      "202/202 [==============================] - 0s 83us/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.1533 - val_accuracy: 0.9804\n",
      "Epoch 171/1000\n",
      "202/202 [==============================] - 0s 89us/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.1224 - val_accuracy: 0.9804\n",
      "Epoch 172/1000\n",
      "202/202 [==============================] - 0s 83us/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.1440 - val_accuracy: 0.9804\n",
      "Epoch 173/1000\n",
      "202/202 [==============================] - 0s 85us/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.1288 - val_accuracy: 0.9804\n",
      "Epoch 174/1000\n",
      "202/202 [==============================] - 0s 89us/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.1304 - val_accuracy: 0.9804\n",
      "Epoch 175/1000\n",
      "202/202 [==============================] - 0s 87us/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.1376 - val_accuracy: 0.9804\n",
      "Epoch 176/1000\n",
      "202/202 [==============================] - 0s 81us/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.1307 - val_accuracy: 0.9804\n",
      "Epoch 177/1000\n",
      "202/202 [==============================] - 0s 97us/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.1384 - val_accuracy: 0.9804\n",
      "Epoch 178/1000\n",
      "202/202 [==============================] - 0s 88us/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.1358 - val_accuracy: 0.9804\n",
      "Epoch 179/1000\n",
      "202/202 [==============================] - 0s 80us/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.1325 - val_accuracy: 0.9804\n",
      "Epoch 180/1000\n",
      "202/202 [==============================] - 0s 93us/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.1373 - val_accuracy: 0.9804\n",
      "Epoch 181/1000\n",
      "202/202 [==============================] - 0s 94us/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.1334 - val_accuracy: 0.9804\n",
      "Epoch 182/1000\n",
      "202/202 [==============================] - 0s 91us/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.1321 - val_accuracy: 0.9804\n",
      "Epoch 183/1000\n",
      "202/202 [==============================] - 0s 80us/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.1494 - val_accuracy: 0.9804\n",
      "Epoch 184/1000\n",
      "202/202 [==============================] - 0s 85us/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.1304 - val_accuracy: 0.9804\n",
      "Epoch 185/1000\n",
      "202/202 [==============================] - 0s 110us/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.1341 - val_accuracy: 0.9804\n",
      "Epoch 186/1000\n",
      "202/202 [==============================] - 0s 102us/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.1536 - val_accuracy: 0.9804\n",
      "Epoch 187/1000\n",
      "202/202 [==============================] - 0s 85us/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.1227 - val_accuracy: 0.9804\n",
      "Epoch 188/1000\n",
      "202/202 [==============================] - 0s 101us/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.1470 - val_accuracy: 0.9804\n",
      "Epoch 189/1000\n",
      "202/202 [==============================] - 0s 94us/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.1409 - val_accuracy: 0.9804\n",
      "Epoch 190/1000\n",
      "202/202 [==============================] - 0s 84us/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.1275 - val_accuracy: 0.9804\n",
      "Epoch 191/1000\n",
      "202/202 [==============================] - 0s 76us/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.1771 - val_accuracy: 0.9804\n",
      "Epoch 192/1000\n",
      "202/202 [==============================] - 0s 85us/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.1133 - val_accuracy: 0.9804\n",
      "Epoch 193/1000\n",
      "202/202 [==============================] - 0s 93us/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.1560 - val_accuracy: 0.9804\n",
      "Epoch 194/1000\n",
      "202/202 [==============================] - 0s 75us/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.1339 - val_accuracy: 0.9804\n",
      "Epoch 195/1000\n",
      "202/202 [==============================] - 0s 119us/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.1371 - val_accuracy: 0.9804\n",
      "Epoch 196/1000\n",
      "202/202 [==============================] - 0s 70us/step - loss: 0.0163 - accuracy: 0.9901 - val_loss: 0.1804 - val_accuracy: 0.9608\n",
      "Epoch 197/1000\n",
      "202/202 [==============================] - 0s 89us/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.1127 - val_accuracy: 0.9804\n",
      "Epoch 198/1000\n",
      "202/202 [==============================] - 0s 114us/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.1711 - val_accuracy: 0.9804\n",
      "Epoch 199/1000\n",
      "202/202 [==============================] - 0s 83us/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.1190 - val_accuracy: 0.9804\n",
      "Epoch 200/1000\n",
      "202/202 [==============================] - 0s 71us/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.1557 - val_accuracy: 0.9804\n",
      "Epoch 201/1000\n",
      "202/202 [==============================] - 0s 86us/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.1361 - val_accuracy: 0.9804\n",
      "Epoch 202/1000\n",
      "202/202 [==============================] - 0s 94us/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.1175 - val_accuracy: 0.9804\n",
      "Epoch 203/1000\n",
      "202/202 [==============================] - 0s 85us/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.1764 - val_accuracy: 0.9804\n",
      "Epoch 204/1000\n",
      "202/202 [==============================] - 0s 86us/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.1357 - val_accuracy: 0.9804\n",
      "Epoch 205/1000\n",
      "202/202 [==============================] - 0s 97us/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.1219 - val_accuracy: 0.9804\n",
      "Epoch 206/1000\n",
      "202/202 [==============================] - 0s 104us/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.1565 - val_accuracy: 0.9804\n",
      "Epoch 207/1000\n",
      "202/202 [==============================] - 0s 93us/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.1304 - val_accuracy: 0.9804\n",
      "Epoch 208/1000\n",
      "202/202 [==============================] - 0s 98us/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.1371 - val_accuracy: 0.9804\n",
      "Epoch 209/1000\n",
      "202/202 [==============================] - 0s 101us/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.1456 - val_accuracy: 0.9804\n",
      "Epoch 210/1000\n",
      "202/202 [==============================] - 0s 92us/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.1302 - val_accuracy: 0.9804\n",
      "Epoch 211/1000\n",
      "202/202 [==============================] - 0s 119us/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.1236 - val_accuracy: 0.9804\n",
      "Epoch 212/1000\n",
      "202/202 [==============================] - 0s 95us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.1671 - val_accuracy: 0.9804\n",
      "Epoch 213/1000\n",
      "202/202 [==============================] - 0s 118us/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.1457 - val_accuracy: 0.9804\n",
      "Epoch 214/1000\n",
      "202/202 [==============================] - 0s 98us/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.1258 - val_accuracy: 0.9804\n",
      "Epoch 215/1000\n",
      "202/202 [==============================] - 0s 118us/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.1448 - val_accuracy: 0.9804\n",
      "Epoch 216/1000\n",
      "202/202 [==============================] - 0s 91us/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.1578 - val_accuracy: 0.9804\n",
      "Epoch 217/1000\n",
      "202/202 [==============================] - 0s 81us/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.1297 - val_accuracy: 0.9804\n",
      "Epoch 218/1000\n",
      "202/202 [==============================] - 0s 81us/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.1448 - val_accuracy: 0.9804\n",
      "Epoch 219/1000\n",
      "202/202 [==============================] - 0s 95us/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.1349 - val_accuracy: 0.9804\n",
      "Epoch 220/1000\n",
      "202/202 [==============================] - 0s 92us/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.1445 - val_accuracy: 0.9804\n",
      "Epoch 221/1000\n",
      "202/202 [==============================] - 0s 85us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.1360 - val_accuracy: 0.9804\n",
      "Epoch 222/1000\n",
      "202/202 [==============================] - 0s 81us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.1394 - val_accuracy: 0.9804\n",
      "Epoch 223/1000\n",
      "202/202 [==============================] - 0s 114us/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.1413 - val_accuracy: 0.9804\n",
      "Epoch 224/1000\n",
      "202/202 [==============================] - 0s 94us/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.1342 - val_accuracy: 0.9804\n",
      "Epoch 225/1000\n",
      "202/202 [==============================] - 0s 78us/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.1517 - val_accuracy: 0.9804\n",
      "Epoch 226/1000\n",
      "202/202 [==============================] - 0s 79us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.1328 - val_accuracy: 0.9804\n",
      "Epoch 227/1000\n",
      "202/202 [==============================] - 0s 94us/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.1278 - val_accuracy: 0.9804\n",
      "Epoch 228/1000\n",
      "202/202 [==============================] - 0s 92us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.1430 - val_accuracy: 0.9804\n",
      "Epoch 229/1000\n",
      "202/202 [==============================] - 0s 81us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.1446 - val_accuracy: 0.9804\n",
      "Epoch 230/1000\n",
      "202/202 [==============================] - 0s 82us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1373 - val_accuracy: 0.9804\n",
      "Epoch 231/1000\n",
      "202/202 [==============================] - 0s 94us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.1500 - val_accuracy: 0.9804\n",
      "Epoch 232/1000\n",
      "202/202 [==============================] - 0s 94us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.1341 - val_accuracy: 0.9804\n",
      "Epoch 233/1000\n",
      "202/202 [==============================] - 0s 80us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1388 - val_accuracy: 0.9804\n",
      "Epoch 234/1000\n",
      "202/202 [==============================] - 0s 92us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.1428 - val_accuracy: 0.9804\n",
      "Epoch 235/1000\n",
      "202/202 [==============================] - 0s 81us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.1439 - val_accuracy: 0.9804\n",
      "Epoch 236/1000\n",
      "202/202 [==============================] - 0s 91us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.1427 - val_accuracy: 0.9804\n",
      "Epoch 237/1000\n",
      "202/202 [==============================] - 0s 98us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.1526 - val_accuracy: 0.9804\n",
      "Epoch 238/1000\n",
      "202/202 [==============================] - 0s 94us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.1334 - val_accuracy: 0.9804\n",
      "Epoch 239/1000\n",
      "202/202 [==============================] - 0s 87us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.1435 - val_accuracy: 0.9804\n",
      "Epoch 240/1000\n",
      "202/202 [==============================] - 0s 81us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.1343 - val_accuracy: 0.9804\n",
      "Epoch 241/1000\n",
      "202/202 [==============================] - 0s 93us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.1453 - val_accuracy: 0.9804\n",
      "Epoch 242/1000\n",
      "202/202 [==============================] - 0s 82us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.1523 - val_accuracy: 0.9804\n",
      "Epoch 243/1000\n",
      "202/202 [==============================] - 0s 94us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.1409 - val_accuracy: 0.9804\n",
      "Epoch 244/1000\n",
      "202/202 [==============================] - 0s 103us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.1404 - val_accuracy: 0.9804\n",
      "Epoch 245/1000\n",
      "202/202 [==============================] - 0s 85us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.1467 - val_accuracy: 0.9804\n",
      "Epoch 246/1000\n",
      "202/202 [==============================] - 0s 102us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.1399 - val_accuracy: 0.9804\n",
      "Epoch 247/1000\n",
      "202/202 [==============================] - 0s 81us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.1453 - val_accuracy: 0.9804\n",
      "Epoch 248/1000\n",
      "202/202 [==============================] - 0s 92us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.1409 - val_accuracy: 0.9804\n",
      "Epoch 249/1000\n",
      "202/202 [==============================] - 0s 83us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.1413 - val_accuracy: 0.9804\n",
      "Epoch 250/1000\n",
      "202/202 [==============================] - 0s 79us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.1442 - val_accuracy: 0.9804\n",
      "Epoch 251/1000\n",
      "202/202 [==============================] - 0s 90us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.1308 - val_accuracy: 0.9804\n",
      "Epoch 252/1000\n",
      "202/202 [==============================] - 0s 103us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.1485 - val_accuracy: 0.9804\n",
      "Epoch 253/1000\n",
      "202/202 [==============================] - 0s 101us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.1311 - val_accuracy: 0.9804\n",
      "Epoch 254/1000\n",
      "202/202 [==============================] - 0s 98us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.1479 - val_accuracy: 0.9804\n",
      "Epoch 255/1000\n",
      "202/202 [==============================] - 0s 84us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.1407 - val_accuracy: 0.9804\n",
      "Epoch 256/1000\n",
      "202/202 [==============================] - 0s 91us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.1426 - val_accuracy: 0.9804\n",
      "Epoch 257/1000\n",
      "202/202 [==============================] - 0s 90us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.1461 - val_accuracy: 0.9804\n",
      "Epoch 258/1000\n",
      "202/202 [==============================] - 0s 95us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.1303 - val_accuracy: 0.9804\n",
      "Epoch 259/1000\n",
      "202/202 [==============================] - 0s 92us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.1488 - val_accuracy: 0.9804\n",
      "Epoch 260/1000\n",
      "202/202 [==============================] - 0s 119us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.1625 - val_accuracy: 0.9804\n",
      "Epoch 261/1000\n",
      "202/202 [==============================] - 0s 117us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.1329 - val_accuracy: 0.9804\n",
      "Epoch 262/1000\n",
      "202/202 [==============================] - 0s 108us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.1433 - val_accuracy: 0.9804\n",
      "Epoch 263/1000\n",
      "202/202 [==============================] - 0s 92us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.1457 - val_accuracy: 0.9804\n",
      "Epoch 264/1000\n",
      "202/202 [==============================] - 0s 90us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.1321 - val_accuracy: 0.9804\n",
      "Epoch 265/1000\n",
      "202/202 [==============================] - 0s 90us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1618 - val_accuracy: 0.9804\n",
      "Epoch 266/1000\n",
      "202/202 [==============================] - 0s 99us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.1457 - val_accuracy: 0.9804\n",
      "Epoch 267/1000\n",
      "202/202 [==============================] - 0s 99us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.1385 - val_accuracy: 0.9804\n",
      "Epoch 268/1000\n",
      "202/202 [==============================] - 0s 98us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1453 - val_accuracy: 0.9804\n",
      "Epoch 269/1000\n",
      "202/202 [==============================] - 0s 101us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1483 - val_accuracy: 0.9804\n",
      "Epoch 270/1000\n",
      "202/202 [==============================] - 0s 106us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.1432 - val_accuracy: 0.9804\n",
      "Epoch 271/1000\n",
      "202/202 [==============================] - 0s 106us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1409 - val_accuracy: 0.9804\n",
      "Epoch 272/1000\n",
      "202/202 [==============================] - 0s 96us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.1559 - val_accuracy: 0.9804\n",
      "Epoch 273/1000\n",
      "202/202 [==============================] - 0s 99us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.1500 - val_accuracy: 0.9804\n",
      "Epoch 274/1000\n",
      "202/202 [==============================] - 0s 90us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.1281 - val_accuracy: 0.9804\n",
      "Epoch 275/1000\n",
      "202/202 [==============================] - 0s 95us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.1478 - val_accuracy: 0.9804\n",
      "Epoch 276/1000\n",
      "202/202 [==============================] - 0s 113us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.1397 - val_accuracy: 0.9804\n",
      "Epoch 277/1000\n",
      "202/202 [==============================] - 0s 96us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.1507 - val_accuracy: 0.9804\n",
      "Epoch 278/1000\n",
      "202/202 [==============================] - 0s 82us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1535 - val_accuracy: 0.9804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 279/1000\n",
      "202/202 [==============================] - 0s 100us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.1475 - val_accuracy: 0.9804\n",
      "Epoch 280/1000\n",
      "202/202 [==============================] - 0s 89us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1498 - val_accuracy: 0.9804\n",
      "Epoch 281/1000\n",
      "202/202 [==============================] - 0s 102us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1491 - val_accuracy: 0.9804\n",
      "Epoch 282/1000\n",
      "202/202 [==============================] - 0s 87us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1536 - val_accuracy: 0.9804\n",
      "Epoch 283/1000\n",
      "202/202 [==============================] - 0s 83us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1508 - val_accuracy: 0.9804\n",
      "Epoch 284/1000\n",
      "202/202 [==============================] - 0s 88us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1430 - val_accuracy: 0.9804\n",
      "Epoch 285/1000\n",
      "202/202 [==============================] - 0s 87us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1501 - val_accuracy: 0.9804\n",
      "Epoch 286/1000\n",
      "202/202 [==============================] - 0s 107us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.1437 - val_accuracy: 0.9804\n",
      "Epoch 287/1000\n",
      "202/202 [==============================] - 0s 94us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.1899 - val_accuracy: 0.9804\n",
      "Epoch 288/1000\n",
      "202/202 [==============================] - 0s 110us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.1402 - val_accuracy: 0.9804\n",
      "Epoch 289/1000\n",
      "202/202 [==============================] - 0s 84us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.1342 - val_accuracy: 0.9804\n",
      "Epoch 290/1000\n",
      "202/202 [==============================] - 0s 96us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1470 - val_accuracy: 0.9804\n",
      "Epoch 291/1000\n",
      "202/202 [==============================] - 0s 76us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1572 - val_accuracy: 0.9804\n",
      "Epoch 292/1000\n",
      "202/202 [==============================] - 0s 89us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.1450 - val_accuracy: 0.9804\n",
      "Epoch 293/1000\n",
      "202/202 [==============================] - 0s 82us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1551 - val_accuracy: 0.9804\n",
      "Epoch 294/1000\n",
      "202/202 [==============================] - 0s 97us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1504 - val_accuracy: 0.9804\n",
      "Epoch 295/1000\n",
      "202/202 [==============================] - 0s 84us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1432 - val_accuracy: 0.9804\n",
      "Epoch 296/1000\n",
      "202/202 [==============================] - 0s 104us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1455 - val_accuracy: 0.9804\n",
      "Epoch 297/1000\n",
      "202/202 [==============================] - 0s 98us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1476 - val_accuracy: 0.9804\n",
      "Epoch 298/1000\n",
      "202/202 [==============================] - 0s 84us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1553 - val_accuracy: 0.9804\n",
      "Epoch 299/1000\n",
      "202/202 [==============================] - 0s 81us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1520 - val_accuracy: 0.9804\n",
      "Epoch 300/1000\n",
      "202/202 [==============================] - 0s 94us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1444 - val_accuracy: 0.9804\n",
      "Epoch 301/1000\n",
      "202/202 [==============================] - 0s 117us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1543 - val_accuracy: 0.9804\n",
      "Epoch 302/1000\n",
      "202/202 [==============================] - 0s 99us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1599 - val_accuracy: 0.9804\n",
      "Epoch 303/1000\n",
      "202/202 [==============================] - 0s 89us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1528 - val_accuracy: 0.9804\n",
      "Epoch 304/1000\n",
      "202/202 [==============================] - 0s 97us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1514 - val_accuracy: 0.9804\n",
      "Epoch 305/1000\n",
      "202/202 [==============================] - 0s 89us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1587 - val_accuracy: 0.9804\n",
      "Epoch 306/1000\n",
      "202/202 [==============================] - 0s 94us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1552 - val_accuracy: 0.9804\n",
      "Epoch 307/1000\n",
      "202/202 [==============================] - 0s 81us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1503 - val_accuracy: 0.9804\n",
      "Epoch 308/1000\n",
      "202/202 [==============================] - 0s 91us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1574 - val_accuracy: 0.9804\n",
      "Epoch 309/1000\n",
      "202/202 [==============================] - 0s 86us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1383 - val_accuracy: 0.9804\n",
      "Epoch 310/1000\n",
      "202/202 [==============================] - 0s 102us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1469 - val_accuracy: 0.9804\n",
      "Epoch 311/1000\n",
      "202/202 [==============================] - 0s 140us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1670 - val_accuracy: 0.9804\n",
      "Epoch 312/1000\n",
      "202/202 [==============================] - 0s 91us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.1268 - val_accuracy: 0.9804\n",
      "Epoch 313/1000\n",
      "202/202 [==============================] - 0s 132us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1657 - val_accuracy: 0.9804\n",
      "Epoch 314/1000\n",
      "202/202 [==============================] - 0s 93us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1748 - val_accuracy: 0.9804\n",
      "Epoch 315/1000\n",
      "202/202 [==============================] - 0s 97us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1519 - val_accuracy: 0.9804\n",
      "Epoch 316/1000\n",
      "202/202 [==============================] - 0s 86us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1451 - val_accuracy: 0.9804\n",
      "Epoch 317/1000\n",
      "202/202 [==============================] - 0s 86us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1665 - val_accuracy: 0.9804\n",
      "Epoch 318/1000\n",
      "202/202 [==============================] - 0s 91us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1706 - val_accuracy: 0.9804\n",
      "Epoch 319/1000\n",
      "202/202 [==============================] - 0s 85us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1532 - val_accuracy: 0.9804\n",
      "Epoch 320/1000\n",
      "202/202 [==============================] - 0s 88us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1544 - val_accuracy: 0.9804\n",
      "Epoch 321/1000\n",
      "202/202 [==============================] - 0s 99us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1618 - val_accuracy: 0.9804\n",
      "Epoch 322/1000\n",
      "202/202 [==============================] - 0s 88us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1742 - val_accuracy: 0.9804\n",
      "Epoch 323/1000\n",
      "202/202 [==============================] - 0s 109us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1533 - val_accuracy: 0.9804\n",
      "Epoch 324/1000\n",
      "202/202 [==============================] - 0s 92us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1523 - val_accuracy: 0.9804\n",
      "Epoch 325/1000\n",
      "202/202 [==============================] - 0s 108us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1711 - val_accuracy: 0.9804\n",
      "Epoch 326/1000\n",
      "202/202 [==============================] - 0s 99us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1628 - val_accuracy: 0.9804\n",
      "Epoch 327/1000\n",
      "202/202 [==============================] - 0s 103us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1502 - val_accuracy: 0.9804\n",
      "Epoch 328/1000\n",
      "202/202 [==============================] - 0s 96us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1647 - val_accuracy: 0.9804\n",
      "Epoch 329/1000\n",
      "202/202 [==============================] - 0s 99us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1569 - val_accuracy: 0.9804\n",
      "Epoch 330/1000\n",
      "202/202 [==============================] - 0s 92us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1498 - val_accuracy: 0.9804\n",
      "Epoch 331/1000\n",
      "202/202 [==============================] - 0s 111us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1683 - val_accuracy: 0.9804\n",
      "Epoch 332/1000\n",
      "202/202 [==============================] - 0s 71us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1587 - val_accuracy: 0.9804\n",
      "Epoch 333/1000\n",
      "202/202 [==============================] - 0s 102us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1574 - val_accuracy: 0.9804\n",
      "Epoch 334/1000\n",
      "202/202 [==============================] - 0s 93us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1521 - val_accuracy: 0.9804\n",
      "Epoch 335/1000\n",
      "202/202 [==============================] - 0s 92us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1633 - val_accuracy: 0.9804\n",
      "Epoch 336/1000\n",
      "202/202 [==============================] - 0s 111us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1449 - val_accuracy: 0.9804\n",
      "Epoch 337/1000\n",
      "202/202 [==============================] - 0s 98us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1645 - val_accuracy: 0.9804\n",
      "Epoch 338/1000\n",
      "202/202 [==============================] - 0s 78us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1610 - val_accuracy: 0.9804\n",
      "Epoch 339/1000\n",
      "202/202 [==============================] - 0s 91us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1420 - val_accuracy: 0.9804\n",
      "Epoch 340/1000\n",
      "202/202 [==============================] - 0s 87us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1771 - val_accuracy: 0.9804\n",
      "Epoch 341/1000\n",
      "202/202 [==============================] - 0s 79us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1672 - val_accuracy: 0.9804\n",
      "Epoch 342/1000\n",
      "202/202 [==============================] - 0s 83us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1616 - val_accuracy: 0.9804\n",
      "Epoch 343/1000\n",
      "202/202 [==============================] - 0s 114us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1691 - val_accuracy: 0.9804\n",
      "Epoch 344/1000\n",
      "202/202 [==============================] - 0s 94us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1533 - val_accuracy: 0.9804\n",
      "Epoch 345/1000\n",
      "202/202 [==============================] - 0s 103us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1650 - val_accuracy: 0.9804\n",
      "Epoch 346/1000\n",
      "202/202 [==============================] - 0s 82us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1717 - val_accuracy: 0.9804\n",
      "Epoch 347/1000\n",
      "202/202 [==============================] - 0s 97us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1563 - val_accuracy: 0.9804\n",
      "Epoch 348/1000\n",
      "202/202 [==============================] - 0s 89us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1702 - val_accuracy: 0.9804\n",
      "Epoch 349/1000\n",
      "202/202 [==============================] - 0s 90us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1656 - val_accuracy: 0.9804\n",
      "Epoch 350/1000\n",
      "202/202 [==============================] - 0s 81us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1556 - val_accuracy: 0.9804\n",
      "Epoch 351/1000\n",
      "202/202 [==============================] - 0s 87us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1655 - val_accuracy: 0.9804\n",
      "Epoch 352/1000\n",
      "202/202 [==============================] - 0s 88us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1640 - val_accuracy: 0.9804\n",
      "Epoch 353/1000\n",
      "202/202 [==============================] - 0s 105us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1468 - val_accuracy: 0.9804\n",
      "Epoch 354/1000\n",
      "202/202 [==============================] - 0s 79us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1704 - val_accuracy: 0.9804\n",
      "Epoch 355/1000\n",
      "202/202 [==============================] - 0s 95us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1719 - val_accuracy: 0.9804\n",
      "Epoch 356/1000\n",
      "202/202 [==============================] - 0s 84us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1604 - val_accuracy: 0.9804\n",
      "Epoch 357/1000\n",
      "202/202 [==============================] - 0s 95us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1465 - val_accuracy: 0.9804\n",
      "Epoch 358/1000\n",
      "202/202 [==============================] - 0s 86us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1773 - val_accuracy: 0.9804\n",
      "Epoch 359/1000\n",
      "202/202 [==============================] - 0s 88us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1790 - val_accuracy: 0.9804\n",
      "Epoch 360/1000\n",
      "202/202 [==============================] - 0s 89us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1579 - val_accuracy: 0.9804\n",
      "Epoch 361/1000\n",
      "202/202 [==============================] - 0s 93us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1578 - val_accuracy: 0.9804\n",
      "Epoch 362/1000\n",
      "202/202 [==============================] - 0s 89us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1722 - val_accuracy: 0.9804\n",
      "Epoch 363/1000\n",
      "202/202 [==============================] - 0s 91us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1702 - val_accuracy: 0.9804\n",
      "Epoch 364/1000\n",
      "202/202 [==============================] - 0s 87us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1674 - val_accuracy: 0.9804\n",
      "Epoch 365/1000\n",
      "202/202 [==============================] - 0s 78us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1614 - val_accuracy: 0.9804\n",
      "Epoch 366/1000\n",
      "202/202 [==============================] - 0s 85us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1612 - val_accuracy: 0.9804\n",
      "Epoch 367/1000\n",
      "202/202 [==============================] - 0s 79us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1701 - val_accuracy: 0.9804\n",
      "Epoch 368/1000\n",
      "202/202 [==============================] - 0s 92us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1741 - val_accuracy: 0.9804\n",
      "Epoch 369/1000\n",
      "202/202 [==============================] - 0s 113us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1604 - val_accuracy: 0.9804\n",
      "Epoch 370/1000\n",
      "202/202 [==============================] - 0s 93us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9804\n",
      "Epoch 371/1000\n",
      "202/202 [==============================] - 0s 77us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1739 - val_accuracy: 0.9804\n",
      "Epoch 372/1000\n",
      "202/202 [==============================] - 0s 101us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1578 - val_accuracy: 0.9804\n",
      "Epoch 373/1000\n",
      "202/202 [==============================] - 0s 89us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1706 - val_accuracy: 0.9804\n",
      "Epoch 374/1000\n",
      "202/202 [==============================] - 0s 106us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1718 - val_accuracy: 0.9804\n",
      "Epoch 375/1000\n",
      "202/202 [==============================] - 0s 94us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1698 - val_accuracy: 0.9804\n",
      "Epoch 376/1000\n",
      "202/202 [==============================] - 0s 97us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1697 - val_accuracy: 0.9804\n",
      "Epoch 377/1000\n",
      "202/202 [==============================] - 0s 87us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1712 - val_accuracy: 0.9804\n",
      "Epoch 378/1000\n",
      "202/202 [==============================] - 0s 91us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1737 - val_accuracy: 0.9804\n",
      "Epoch 379/1000\n",
      "202/202 [==============================] - 0s 88us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1613 - val_accuracy: 0.9804\n",
      "Epoch 380/1000\n",
      "202/202 [==============================] - 0s 91us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1745 - val_accuracy: 0.9804\n",
      "Epoch 381/1000\n",
      "202/202 [==============================] - 0s 86us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1705 - val_accuracy: 0.9804\n",
      "Epoch 382/1000\n",
      "202/202 [==============================] - 0s 74us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1679 - val_accuracy: 0.9804\n",
      "Epoch 383/1000\n",
      "202/202 [==============================] - 0s 99us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1652 - val_accuracy: 0.9804\n",
      "Epoch 384/1000\n",
      "202/202 [==============================] - 0s 80us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1764 - val_accuracy: 0.9804\n",
      "Epoch 385/1000\n",
      "202/202 [==============================] - 0s 85us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1736 - val_accuracy: 0.9804\n",
      "Epoch 386/1000\n",
      "202/202 [==============================] - 0s 102us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1667 - val_accuracy: 0.9804\n",
      "Epoch 387/1000\n",
      "202/202 [==============================] - 0s 101us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1618 - val_accuracy: 0.9804\n",
      "Epoch 388/1000\n",
      "202/202 [==============================] - 0s 103us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1764 - val_accuracy: 0.9804\n",
      "Epoch 389/1000\n",
      "202/202 [==============================] - 0s 106us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1748 - val_accuracy: 0.9804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 390/1000\n",
      "202/202 [==============================] - 0s 73us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1714 - val_accuracy: 0.9804\n",
      "Epoch 391/1000\n",
      "202/202 [==============================] - 0s 96us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1814 - val_accuracy: 0.9804\n",
      "Epoch 392/1000\n",
      "202/202 [==============================] - 0s 93us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1691 - val_accuracy: 0.9804\n",
      "Epoch 393/1000\n",
      "202/202 [==============================] - 0s 80us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1736 - val_accuracy: 0.9804\n",
      "Epoch 394/1000\n",
      "202/202 [==============================] - 0s 80us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1738 - val_accuracy: 0.9804\n",
      "Epoch 395/1000\n",
      "202/202 [==============================] - 0s 86us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1643 - val_accuracy: 0.9804\n",
      "Epoch 396/1000\n",
      "202/202 [==============================] - 0s 94us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1740 - val_accuracy: 0.9804\n",
      "Epoch 397/1000\n",
      "202/202 [==============================] - 0s 102us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1909 - val_accuracy: 0.9804\n",
      "Epoch 398/1000\n",
      "202/202 [==============================] - 0s 109us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1804 - val_accuracy: 0.9804\n",
      "Epoch 399/1000\n",
      "202/202 [==============================] - 0s 90us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1672 - val_accuracy: 0.9804\n",
      "Epoch 400/1000\n",
      "202/202 [==============================] - 0s 101us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1655 - val_accuracy: 0.9804\n",
      "Epoch 401/1000\n",
      "202/202 [==============================] - 0s 88us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1831 - val_accuracy: 0.9804\n",
      "Epoch 402/1000\n",
      "202/202 [==============================] - 0s 91us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1809 - val_accuracy: 0.9804\n",
      "Epoch 403/1000\n",
      "202/202 [==============================] - 0s 95us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1686 - val_accuracy: 0.9804\n",
      "Epoch 404/1000\n",
      "202/202 [==============================] - 0s 77us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1702 - val_accuracy: 0.9804\n",
      "Epoch 405/1000\n",
      "202/202 [==============================] - 0s 119us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1824 - val_accuracy: 0.9804\n",
      "Epoch 406/1000\n",
      "202/202 [==============================] - 0s 100us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1778 - val_accuracy: 0.9804\n",
      "Epoch 407/1000\n",
      "202/202 [==============================] - 0s 101us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1724 - val_accuracy: 0.9804\n",
      "Epoch 408/1000\n",
      "202/202 [==============================] - 0s 90us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1769 - val_accuracy: 0.9804\n",
      "Epoch 409/1000\n",
      "202/202 [==============================] - 0s 109us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1797 - val_accuracy: 0.9804\n",
      "Epoch 410/1000\n",
      "202/202 [==============================] - 0s 95us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1712 - val_accuracy: 0.9804\n",
      "Epoch 411/1000\n",
      "202/202 [==============================] - 0s 93us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1842 - val_accuracy: 0.9804\n",
      "Epoch 412/1000\n",
      "202/202 [==============================] - 0s 85us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1795 - val_accuracy: 0.9804\n",
      "Epoch 413/1000\n",
      "202/202 [==============================] - 0s 88us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1790 - val_accuracy: 0.9804\n",
      "Epoch 414/1000\n",
      "202/202 [==============================] - 0s 87us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1751 - val_accuracy: 0.9804\n",
      "Epoch 415/1000\n",
      "202/202 [==============================] - 0s 81us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1722 - val_accuracy: 0.9804\n",
      "Epoch 416/1000\n",
      "202/202 [==============================] - 0s 100us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1698 - val_accuracy: 0.9804\n",
      "Epoch 417/1000\n",
      "202/202 [==============================] - 0s 90us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1808 - val_accuracy: 0.9804\n",
      "Epoch 418/1000\n",
      "202/202 [==============================] - 0s 78us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1860 - val_accuracy: 0.9804\n",
      "Epoch 419/1000\n",
      "202/202 [==============================] - 0s 84us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1719 - val_accuracy: 0.9804\n",
      "Epoch 420/1000\n",
      "202/202 [==============================] - 0s 84us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1817 - val_accuracy: 0.9804\n",
      "Epoch 421/1000\n",
      "202/202 [==============================] - 0s 78us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1824 - val_accuracy: 0.9804\n",
      "Epoch 422/1000\n",
      "202/202 [==============================] - 0s 105us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1809 - val_accuracy: 0.9804\n",
      "Epoch 423/1000\n",
      "202/202 [==============================] - 0s 112us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1808 - val_accuracy: 0.9804\n",
      "Epoch 424/1000\n",
      "202/202 [==============================] - 0s 105us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1844 - val_accuracy: 0.9804\n",
      "Epoch 425/1000\n",
      "202/202 [==============================] - 0s 116us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1832 - val_accuracy: 0.9804\n",
      "Epoch 426/1000\n",
      "202/202 [==============================] - 0s 78us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1762 - val_accuracy: 0.9804\n",
      "Epoch 427/1000\n",
      "202/202 [==============================] - 0s 69us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1715 - val_accuracy: 0.9804\n",
      "Epoch 428/1000\n",
      "202/202 [==============================] - 0s 145us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1821 - val_accuracy: 0.9804\n",
      "Epoch 429/1000\n",
      "202/202 [==============================] - 0s 90us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1862 - val_accuracy: 0.9804\n",
      "Epoch 430/1000\n",
      "202/202 [==============================] - 0s 105us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1889 - val_accuracy: 0.9804\n",
      "Epoch 431/1000\n",
      "202/202 [==============================] - 0s 77us/step - loss: 9.7261e-04 - accuracy: 1.0000 - val_loss: 0.1745 - val_accuracy: 0.9804\n",
      "Epoch 432/1000\n",
      "202/202 [==============================] - 0s 83us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1751 - val_accuracy: 0.9804\n",
      "Epoch 433/1000\n",
      "202/202 [==============================] - 0s 89us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1885 - val_accuracy: 0.9804\n",
      "Epoch 434/1000\n",
      "202/202 [==============================] - 0s 89us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1878 - val_accuracy: 0.9804\n",
      "Epoch 435/1000\n",
      "202/202 [==============================] - 0s 88us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1516 - val_accuracy: 0.9804\n",
      "Epoch 436/1000\n",
      "202/202 [==============================] - 0s 74us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1981 - val_accuracy: 0.9804\n",
      "Epoch 437/1000\n",
      "202/202 [==============================] - 0s 93us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1831 - val_accuracy: 0.9804\n",
      "Epoch 438/1000\n",
      "202/202 [==============================] - 0s 100us/step - loss: 9.6144e-04 - accuracy: 1.0000 - val_loss: 0.1838 - val_accuracy: 0.9804\n",
      "Epoch 439/1000\n",
      "202/202 [==============================] - 0s 94us/step - loss: 9.8191e-04 - accuracy: 1.0000 - val_loss: 0.1824 - val_accuracy: 0.9804\n",
      "Epoch 440/1000\n",
      "202/202 [==============================] - 0s 99us/step - loss: 9.9981e-04 - accuracy: 1.0000 - val_loss: 0.1774 - val_accuracy: 0.9804\n",
      "Epoch 441/1000\n",
      "202/202 [==============================] - 0s 105us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1931 - val_accuracy: 0.9804\n",
      "Epoch 442/1000\n",
      "202/202 [==============================] - 0s 103us/step - loss: 9.9858e-04 - accuracy: 1.0000 - val_loss: 0.1854 - val_accuracy: 0.9804\n",
      "Epoch 443/1000\n",
      "202/202 [==============================] - 0s 93us/step - loss: 9.4697e-04 - accuracy: 1.0000 - val_loss: 0.1871 - val_accuracy: 0.9804\n",
      "Epoch 444/1000\n",
      "202/202 [==============================] - 0s 93us/step - loss: 9.3694e-04 - accuracy: 1.0000 - val_loss: 0.1773 - val_accuracy: 0.9804\n",
      "Epoch 445/1000\n",
      "202/202 [==============================] - 0s 92us/step - loss: 9.6639e-04 - accuracy: 1.0000 - val_loss: 0.1852 - val_accuracy: 0.9804\n",
      "Epoch 446/1000\n",
      "202/202 [==============================] - 0s 85us/step - loss: 9.2159e-04 - accuracy: 1.0000 - val_loss: 0.1860 - val_accuracy: 0.9804\n",
      "Epoch 447/1000\n",
      "202/202 [==============================] - 0s 98us/step - loss: 9.0901e-04 - accuracy: 1.0000 - val_loss: 0.1891 - val_accuracy: 0.9804\n",
      "Epoch 448/1000\n",
      "202/202 [==============================] - 0s 82us/step - loss: 9.1547e-04 - accuracy: 1.0000 - val_loss: 0.1935 - val_accuracy: 0.9804\n",
      "Epoch 449/1000\n",
      "202/202 [==============================] - 0s 97us/step - loss: 9.0907e-04 - accuracy: 1.0000 - val_loss: 0.1860 - val_accuracy: 0.9804\n",
      "Epoch 450/1000\n",
      "202/202 [==============================] - 0s 90us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1763 - val_accuracy: 0.9804\n",
      "Epoch 451/1000\n",
      "202/202 [==============================] - 0s 72us/step - loss: 8.8916e-04 - accuracy: 1.0000 - val_loss: 0.1980 - val_accuracy: 0.9804\n",
      "Epoch 452/1000\n",
      "202/202 [==============================] - 0s 88us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1978 - val_accuracy: 0.9804\n",
      "Epoch 453/1000\n",
      "202/202 [==============================] - 0s 95us/step - loss: 8.9927e-04 - accuracy: 1.0000 - val_loss: 0.1851 - val_accuracy: 0.9804\n",
      "Epoch 454/1000\n",
      "202/202 [==============================] - 0s 100us/step - loss: 9.4716e-04 - accuracy: 1.0000 - val_loss: 0.1763 - val_accuracy: 0.9804\n",
      "Epoch 455/1000\n",
      "202/202 [==============================] - 0s 97us/step - loss: 9.7507e-04 - accuracy: 1.0000 - val_loss: 0.1884 - val_accuracy: 0.9804\n",
      "Epoch 456/1000\n",
      "202/202 [==============================] - 0s 95us/step - loss: 8.5923e-04 - accuracy: 1.0000 - val_loss: 0.1846 - val_accuracy: 0.9804\n",
      "Epoch 457/1000\n",
      "202/202 [==============================] - 0s 87us/step - loss: 9.0351e-04 - accuracy: 1.0000 - val_loss: 0.1874 - val_accuracy: 0.9804\n",
      "Epoch 458/1000\n",
      "202/202 [==============================] - 0s 92us/step - loss: 8.3676e-04 - accuracy: 1.0000 - val_loss: 0.1924 - val_accuracy: 0.9804\n",
      "Epoch 459/1000\n",
      "202/202 [==============================] - 0s 79us/step - loss: 9.0690e-04 - accuracy: 1.0000 - val_loss: 0.1896 - val_accuracy: 0.9804\n",
      "Epoch 460/1000\n",
      "202/202 [==============================] - 0s 67us/step - loss: 8.6017e-04 - accuracy: 1.0000 - val_loss: 0.1897 - val_accuracy: 0.9804\n",
      "Epoch 461/1000\n",
      "202/202 [==============================] - 0s 70us/step - loss: 8.3229e-04 - accuracy: 1.0000 - val_loss: 0.1973 - val_accuracy: 0.9804\n",
      "Epoch 462/1000\n",
      "202/202 [==============================] - 0s 86us/step - loss: 8.6873e-04 - accuracy: 1.0000 - val_loss: 0.1907 - val_accuracy: 0.9804\n",
      "Epoch 463/1000\n",
      "202/202 [==============================] - 0s 63us/step - loss: 8.3865e-04 - accuracy: 1.0000 - val_loss: 0.1904 - val_accuracy: 0.9804\n",
      "Epoch 464/1000\n",
      "202/202 [==============================] - 0s 73us/step - loss: 8.6408e-04 - accuracy: 1.0000 - val_loss: 0.1957 - val_accuracy: 0.9804\n",
      "Epoch 465/1000\n",
      "202/202 [==============================] - 0s 74us/step - loss: 8.3491e-04 - accuracy: 1.0000 - val_loss: 0.1914 - val_accuracy: 0.9804\n",
      "Epoch 466/1000\n",
      "202/202 [==============================] - 0s 67us/step - loss: 8.6795e-04 - accuracy: 1.0000 - val_loss: 0.1823 - val_accuracy: 0.9804\n",
      "Epoch 467/1000\n",
      "202/202 [==============================] - 0s 83us/step - loss: 8.7627e-04 - accuracy: 1.0000 - val_loss: 0.2002 - val_accuracy: 0.9804\n",
      "Epoch 468/1000\n",
      "202/202 [==============================] - 0s 100us/step - loss: 8.6917e-04 - accuracy: 1.0000 - val_loss: 0.1954 - val_accuracy: 0.9804\n",
      "Epoch 469/1000\n",
      "202/202 [==============================] - 0s 102us/step - loss: 8.2839e-04 - accuracy: 1.0000 - val_loss: 0.1783 - val_accuracy: 0.9804\n",
      "Epoch 470/1000\n",
      "202/202 [==============================] - 0s 117us/step - loss: 9.6679e-04 - accuracy: 1.0000 - val_loss: 0.1852 - val_accuracy: 0.9804\n",
      "Epoch 471/1000\n",
      "202/202 [==============================] - 0s 94us/step - loss: 8.0926e-04 - accuracy: 1.0000 - val_loss: 0.1935 - val_accuracy: 0.9804\n",
      "Epoch 472/1000\n",
      "202/202 [==============================] - 0s 108us/step - loss: 7.9846e-04 - accuracy: 1.0000 - val_loss: 0.1985 - val_accuracy: 0.9804\n",
      "Epoch 473/1000\n",
      "202/202 [==============================] - 0s 98us/step - loss: 8.6468e-04 - accuracy: 1.0000 - val_loss: 0.1922 - val_accuracy: 0.9804\n",
      "Epoch 474/1000\n",
      "202/202 [==============================] - 0s 96us/step - loss: 8.0458e-04 - accuracy: 1.0000 - val_loss: 0.1961 - val_accuracy: 0.9804\n",
      "Epoch 475/1000\n",
      "202/202 [==============================] - 0s 98us/step - loss: 7.8660e-04 - accuracy: 1.0000 - val_loss: 0.2010 - val_accuracy: 0.9804\n",
      "Epoch 476/1000\n",
      "202/202 [==============================] - 0s 89us/step - loss: 8.5161e-04 - accuracy: 1.0000 - val_loss: 0.2001 - val_accuracy: 0.9804\n",
      "Epoch 477/1000\n",
      "202/202 [==============================] - 0s 75us/step - loss: 7.5068e-04 - accuracy: 1.0000 - val_loss: 0.1906 - val_accuracy: 0.9804\n",
      "Epoch 478/1000\n",
      "202/202 [==============================] - 0s 91us/step - loss: 7.8205e-04 - accuracy: 1.0000 - val_loss: 0.1945 - val_accuracy: 0.9804\n",
      "Epoch 479/1000\n",
      "202/202 [==============================] - 0s 92us/step - loss: 7.7256e-04 - accuracy: 1.0000 - val_loss: 0.2015 - val_accuracy: 0.9804\n",
      "Epoch 480/1000\n",
      "202/202 [==============================] - 0s 117us/step - loss: 8.3306e-04 - accuracy: 1.0000 - val_loss: 0.1949 - val_accuracy: 0.9804\n",
      "Epoch 481/1000\n",
      "202/202 [==============================] - 0s 112us/step - loss: 8.3239e-04 - accuracy: 1.0000 - val_loss: 0.2031 - val_accuracy: 0.9804\n",
      "Epoch 482/1000\n",
      "202/202 [==============================] - 0s 102us/step - loss: 7.8540e-04 - accuracy: 1.0000 - val_loss: 0.1944 - val_accuracy: 0.9804\n",
      "Epoch 483/1000\n",
      "202/202 [==============================] - 0s 103us/step - loss: 7.5894e-04 - accuracy: 1.0000 - val_loss: 0.1933 - val_accuracy: 0.9804\n",
      "Epoch 484/1000\n",
      "202/202 [==============================] - 0s 93us/step - loss: 7.4892e-04 - accuracy: 1.0000 - val_loss: 0.1954 - val_accuracy: 0.9804\n",
      "Epoch 485/1000\n",
      "202/202 [==============================] - 0s 112us/step - loss: 7.5118e-04 - accuracy: 1.0000 - val_loss: 0.1961 - val_accuracy: 0.9804\n",
      "Epoch 486/1000\n",
      "202/202 [==============================] - 0s 87us/step - loss: 7.4330e-04 - accuracy: 1.0000 - val_loss: 0.1982 - val_accuracy: 0.9804\n",
      "Epoch 487/1000\n",
      "202/202 [==============================] - 0s 101us/step - loss: 7.4033e-04 - accuracy: 1.0000 - val_loss: 0.1986 - val_accuracy: 0.9804\n",
      "Epoch 488/1000\n",
      "202/202 [==============================] - 0s 83us/step - loss: 7.7585e-04 - accuracy: 1.0000 - val_loss: 0.2027 - val_accuracy: 0.9804\n",
      "Epoch 489/1000\n",
      "202/202 [==============================] - 0s 98us/step - loss: 7.0179e-04 - accuracy: 1.0000 - val_loss: 0.1874 - val_accuracy: 0.9804\n",
      "Epoch 490/1000\n",
      "202/202 [==============================] - 0s 97us/step - loss: 7.8321e-04 - accuracy: 1.0000 - val_loss: 0.1889 - val_accuracy: 0.9804\n",
      "Epoch 491/1000\n",
      "202/202 [==============================] - 0s 95us/step - loss: 7.5538e-04 - accuracy: 1.0000 - val_loss: 0.1933 - val_accuracy: 0.9804\n",
      "Epoch 492/1000\n",
      "202/202 [==============================] - 0s 111us/step - loss: 7.2933e-04 - accuracy: 1.0000 - val_loss: 0.2059 - val_accuracy: 0.9804\n",
      "Epoch 493/1000\n",
      "202/202 [==============================] - 0s 96us/step - loss: 7.7615e-04 - accuracy: 1.0000 - val_loss: 0.2039 - val_accuracy: 0.9804\n",
      "Epoch 494/1000\n",
      "202/202 [==============================] - 0s 110us/step - loss: 6.7706e-04 - accuracy: 1.0000 - val_loss: 0.1859 - val_accuracy: 0.9804\n",
      "Epoch 495/1000\n",
      "202/202 [==============================] - 0s 100us/step - loss: 8.5787e-04 - accuracy: 1.0000 - val_loss: 0.1898 - val_accuracy: 0.9804\n",
      "Epoch 496/1000\n",
      "202/202 [==============================] - 0s 92us/step - loss: 7.3705e-04 - accuracy: 1.0000 - val_loss: 0.2165 - val_accuracy: 0.9804\n",
      "Epoch 497/1000\n",
      "202/202 [==============================] - 0s 92us/step - loss: 8.8793e-04 - accuracy: 1.0000 - val_loss: 0.2013 - val_accuracy: 0.9804\n",
      "Epoch 498/1000\n",
      "202/202 [==============================] - 0s 101us/step - loss: 6.9954e-04 - accuracy: 1.0000 - val_loss: 0.1980 - val_accuracy: 0.9804\n",
      "Epoch 499/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202/202 [==============================] - 0s 85us/step - loss: 7.2102e-04 - accuracy: 1.0000 - val_loss: 0.1996 - val_accuracy: 0.9804\n",
      "Epoch 500/1000\n",
      "202/202 [==============================] - 0s 105us/step - loss: 7.2583e-04 - accuracy: 1.0000 - val_loss: 0.1943 - val_accuracy: 0.9804\n",
      "Epoch 501/1000\n",
      "202/202 [==============================] - 0s 103us/step - loss: 7.0675e-04 - accuracy: 1.0000 - val_loss: 0.1981 - val_accuracy: 0.9804\n",
      "Epoch 502/1000\n",
      "202/202 [==============================] - 0s 86us/step - loss: 8.3570e-04 - accuracy: 1.0000 - val_loss: 0.2113 - val_accuracy: 0.9804\n",
      "Epoch 503/1000\n",
      "202/202 [==============================] - 0s 87us/step - loss: 8.6196e-04 - accuracy: 1.0000 - val_loss: 0.1912 - val_accuracy: 0.9804\n",
      "Epoch 504/1000\n",
      "202/202 [==============================] - 0s 91us/step - loss: 7.8574e-04 - accuracy: 1.0000 - val_loss: 0.2088 - val_accuracy: 0.9804\n",
      "Epoch 505/1000\n",
      "202/202 [==============================] - 0s 84us/step - loss: 7.4455e-04 - accuracy: 1.0000 - val_loss: 0.2022 - val_accuracy: 0.9804\n",
      "Epoch 506/1000\n",
      "202/202 [==============================] - 0s 86us/step - loss: 6.6590e-04 - accuracy: 1.0000 - val_loss: 0.1985 - val_accuracy: 0.9804\n",
      "Epoch 507/1000\n",
      "202/202 [==============================] - 0s 90us/step - loss: 6.5639e-04 - accuracy: 1.0000 - val_loss: 0.1975 - val_accuracy: 0.9804\n",
      "Epoch 508/1000\n",
      "202/202 [==============================] - 0s 104us/step - loss: 6.9054e-04 - accuracy: 1.0000 - val_loss: 0.1983 - val_accuracy: 0.9804\n",
      "Epoch 509/1000\n",
      "202/202 [==============================] - 0s 83us/step - loss: 6.8491e-04 - accuracy: 1.0000 - val_loss: 0.2109 - val_accuracy: 0.9804\n",
      "Epoch 510/1000\n",
      "202/202 [==============================] - 0s 107us/step - loss: 7.9062e-04 - accuracy: 1.0000 - val_loss: 0.1923 - val_accuracy: 0.9804\n",
      "Epoch 511/1000\n",
      "202/202 [==============================] - 0s 85us/step - loss: 6.7867e-04 - accuracy: 1.0000 - val_loss: 0.2083 - val_accuracy: 0.9804\n",
      "Epoch 512/1000\n",
      "202/202 [==============================] - 0s 111us/step - loss: 6.8024e-04 - accuracy: 1.0000 - val_loss: 0.2050 - val_accuracy: 0.9804\n",
      "Epoch 513/1000\n",
      "202/202 [==============================] - 0s 95us/step - loss: 6.6712e-04 - accuracy: 1.0000 - val_loss: 0.2049 - val_accuracy: 0.9804\n",
      "Epoch 514/1000\n",
      "202/202 [==============================] - 0s 101us/step - loss: 6.5560e-04 - accuracy: 1.0000 - val_loss: 0.1998 - val_accuracy: 0.9804\n",
      "Epoch 515/1000\n",
      "202/202 [==============================] - 0s 101us/step - loss: 6.6561e-04 - accuracy: 1.0000 - val_loss: 0.1906 - val_accuracy: 0.9804\n",
      "Epoch 516/1000\n",
      "202/202 [==============================] - 0s 98us/step - loss: 6.9103e-04 - accuracy: 1.0000 - val_loss: 0.1998 - val_accuracy: 0.9804\n",
      "Epoch 517/1000\n",
      "202/202 [==============================] - 0s 98us/step - loss: 6.3821e-04 - accuracy: 1.0000 - val_loss: 0.2049 - val_accuracy: 0.9804\n",
      "Epoch 518/1000\n",
      "202/202 [==============================] - 0s 112us/step - loss: 6.3391e-04 - accuracy: 1.0000 - val_loss: 0.2032 - val_accuracy: 0.9804\n",
      "Epoch 519/1000\n",
      "202/202 [==============================] - 0s 102us/step - loss: 6.3791e-04 - accuracy: 1.0000 - val_loss: 0.2065 - val_accuracy: 0.9804\n",
      "Epoch 520/1000\n",
      "202/202 [==============================] - 0s 105us/step - loss: 6.8626e-04 - accuracy: 1.0000 - val_loss: 0.2050 - val_accuracy: 0.9804\n",
      "Epoch 521/1000\n",
      "202/202 [==============================] - 0s 108us/step - loss: 7.4181e-04 - accuracy: 1.0000 - val_loss: 0.1797 - val_accuracy: 0.9804\n",
      "Epoch 522/1000\n",
      "202/202 [==============================] - 0s 112us/step - loss: 8.7498e-04 - accuracy: 1.0000 - val_loss: 0.2140 - val_accuracy: 0.9804\n",
      "Epoch 523/1000\n",
      "202/202 [==============================] - 0s 74us/step - loss: 7.3574e-04 - accuracy: 1.0000 - val_loss: 0.2149 - val_accuracy: 0.9804\n",
      "Epoch 524/1000\n",
      "202/202 [==============================] - 0s 85us/step - loss: 6.7580e-04 - accuracy: 1.0000 - val_loss: 0.1956 - val_accuracy: 0.9804\n",
      "Epoch 525/1000\n",
      "202/202 [==============================] - 0s 108us/step - loss: 6.7697e-04 - accuracy: 1.0000 - val_loss: 0.1995 - val_accuracy: 0.9804\n",
      "Epoch 526/1000\n",
      "202/202 [==============================] - 0s 98us/step - loss: 6.7873e-04 - accuracy: 1.0000 - val_loss: 0.2138 - val_accuracy: 0.9804\n",
      "Epoch 527/1000\n",
      "202/202 [==============================] - 0s 79us/step - loss: 5.8914e-04 - accuracy: 1.0000 - val_loss: 0.1940 - val_accuracy: 0.9804\n",
      "Epoch 528/1000\n",
      "202/202 [==============================] - 0s 74us/step - loss: 6.6522e-04 - accuracy: 1.0000 - val_loss: 0.1971 - val_accuracy: 0.9804\n",
      "Epoch 529/1000\n",
      "202/202 [==============================] - 0s 95us/step - loss: 6.2583e-04 - accuracy: 1.0000 - val_loss: 0.2099 - val_accuracy: 0.9804\n",
      "Epoch 530/1000\n",
      "202/202 [==============================] - 0s 103us/step - loss: 6.3169e-04 - accuracy: 1.0000 - val_loss: 0.2121 - val_accuracy: 0.9804\n",
      "Epoch 531/1000\n",
      "202/202 [==============================] - 0s 95us/step - loss: 6.0354e-04 - accuracy: 1.0000 - val_loss: 0.2068 - val_accuracy: 0.9804\n",
      "Epoch 532/1000\n",
      "202/202 [==============================] - 0s 99us/step - loss: 6.5406e-04 - accuracy: 1.0000 - val_loss: 0.2072 - val_accuracy: 0.9804\n",
      "Epoch 533/1000\n",
      "202/202 [==============================] - 0s 89us/step - loss: 6.6818e-04 - accuracy: 1.0000 - val_loss: 0.1823 - val_accuracy: 0.9804\n",
      "Epoch 534/1000\n",
      "202/202 [==============================] - 0s 100us/step - loss: 8.0791e-04 - accuracy: 1.0000 - val_loss: 0.2033 - val_accuracy: 0.9804\n",
      "Epoch 535/1000\n",
      "202/202 [==============================] - 0s 82us/step - loss: 5.8091e-04 - accuracy: 1.0000 - val_loss: 0.2176 - val_accuracy: 0.9804\n",
      "Epoch 536/1000\n",
      "202/202 [==============================] - 0s 78us/step - loss: 6.7702e-04 - accuracy: 1.0000 - val_loss: 0.2126 - val_accuracy: 0.9804\n",
      "Epoch 537/1000\n",
      "202/202 [==============================] - 0s 94us/step - loss: 6.0992e-04 - accuracy: 1.0000 - val_loss: 0.1999 - val_accuracy: 0.9804\n",
      "Epoch 538/1000\n",
      "202/202 [==============================] - 0s 113us/step - loss: 6.4211e-04 - accuracy: 1.0000 - val_loss: 0.2036 - val_accuracy: 0.9804\n",
      "Epoch 539/1000\n",
      "202/202 [==============================] - 0s 89us/step - loss: 5.6273e-04 - accuracy: 1.0000 - val_loss: 0.2166 - val_accuracy: 0.9804\n",
      "Epoch 540/1000\n",
      "202/202 [==============================] - 0s 88us/step - loss: 6.0984e-04 - accuracy: 1.0000 - val_loss: 0.2139 - val_accuracy: 0.9804\n",
      "Epoch 541/1000\n",
      "202/202 [==============================] - 0s 95us/step - loss: 6.0688e-04 - accuracy: 1.0000 - val_loss: 0.1882 - val_accuracy: 0.9804\n",
      "Epoch 542/1000\n",
      "202/202 [==============================] - 0s 74us/step - loss: 7.2940e-04 - accuracy: 1.0000 - val_loss: 0.2071 - val_accuracy: 0.9804\n",
      "Epoch 543/1000\n",
      "202/202 [==============================] - 0s 101us/step - loss: 5.5204e-04 - accuracy: 1.0000 - val_loss: 0.2190 - val_accuracy: 0.9804\n",
      "Epoch 544/1000\n",
      "202/202 [==============================] - 0s 113us/step - loss: 5.4974e-04 - accuracy: 1.0000 - val_loss: 0.2047 - val_accuracy: 0.9804\n",
      "Epoch 545/1000\n",
      "202/202 [==============================] - 0s 92us/step - loss: 6.0684e-04 - accuracy: 1.0000 - val_loss: 0.2022 - val_accuracy: 0.9804\n",
      "Epoch 546/1000\n",
      "202/202 [==============================] - 0s 95us/step - loss: 5.4498e-04 - accuracy: 1.0000 - val_loss: 0.2143 - val_accuracy: 0.9804\n",
      "Epoch 547/1000\n",
      "202/202 [==============================] - 0s 86us/step - loss: 5.5136e-04 - accuracy: 1.0000 - val_loss: 0.2128 - val_accuracy: 0.9804\n",
      "Epoch 548/1000\n",
      "202/202 [==============================] - 0s 89us/step - loss: 5.3695e-04 - accuracy: 1.0000 - val_loss: 0.2117 - val_accuracy: 0.9804\n",
      "Epoch 549/1000\n",
      "202/202 [==============================] - 0s 86us/step - loss: 5.3637e-04 - accuracy: 1.0000 - val_loss: 0.2100 - val_accuracy: 0.9804\n",
      "Epoch 550/1000\n",
      "202/202 [==============================] - 0s 86us/step - loss: 5.4207e-04 - accuracy: 1.0000 - val_loss: 0.2074 - val_accuracy: 0.9804\n",
      "Epoch 551/1000\n",
      "202/202 [==============================] - 0s 101us/step - loss: 5.3752e-04 - accuracy: 1.0000 - val_loss: 0.2248 - val_accuracy: 0.9804\n",
      "Epoch 552/1000\n",
      "202/202 [==============================] - 0s 88us/step - loss: 6.5320e-04 - accuracy: 1.0000 - val_loss: 0.2177 - val_accuracy: 0.9804\n",
      "Epoch 553/1000\n",
      "202/202 [==============================] - 0s 97us/step - loss: 5.5474e-04 - accuracy: 1.0000 - val_loss: 0.2044 - val_accuracy: 0.9804\n",
      "Epoch 554/1000\n",
      "202/202 [==============================] - 0s 94us/step - loss: 5.7009e-04 - accuracy: 1.0000 - val_loss: 0.2128 - val_accuracy: 0.9804\n",
      "Epoch 555/1000\n",
      "202/202 [==============================] - 0s 85us/step - loss: 5.5867e-04 - accuracy: 1.0000 - val_loss: 0.2065 - val_accuracy: 0.9804\n",
      "Epoch 556/1000\n",
      "202/202 [==============================] - 0s 87us/step - loss: 5.4952e-04 - accuracy: 1.0000 - val_loss: 0.2127 - val_accuracy: 0.9804\n",
      "Epoch 557/1000\n",
      "202/202 [==============================] - 0s 89us/step - loss: 5.1400e-04 - accuracy: 1.0000 - val_loss: 0.2139 - val_accuracy: 0.9804\n",
      "Epoch 558/1000\n",
      "202/202 [==============================] - 0s 86us/step - loss: 5.1124e-04 - accuracy: 1.0000 - val_loss: 0.2156 - val_accuracy: 0.9804\n",
      "Epoch 559/1000\n",
      "202/202 [==============================] - 0s 77us/step - loss: 5.0477e-04 - accuracy: 1.0000 - val_loss: 0.2157 - val_accuracy: 0.9804\n",
      "Epoch 560/1000\n",
      "202/202 [==============================] - 0s 81us/step - loss: 5.3401e-04 - accuracy: 1.0000 - val_loss: 0.2158 - val_accuracy: 0.9804\n",
      "Epoch 561/1000\n",
      "202/202 [==============================] - 0s 81us/step - loss: 5.0259e-04 - accuracy: 1.0000 - val_loss: 0.2098 - val_accuracy: 0.9804\n",
      "Epoch 562/1000\n",
      "202/202 [==============================] - 0s 82us/step - loss: 5.1267e-04 - accuracy: 1.0000 - val_loss: 0.2139 - val_accuracy: 0.9804\n",
      "Epoch 563/1000\n",
      "202/202 [==============================] - 0s 90us/step - loss: 5.3478e-04 - accuracy: 1.0000 - val_loss: 0.2229 - val_accuracy: 0.9804\n",
      "Epoch 564/1000\n",
      "202/202 [==============================] - 0s 101us/step - loss: 5.3078e-04 - accuracy: 1.0000 - val_loss: 0.2101 - val_accuracy: 0.9804\n",
      "Epoch 565/1000\n",
      "202/202 [==============================] - 0s 82us/step - loss: 5.0595e-04 - accuracy: 1.0000 - val_loss: 0.2132 - val_accuracy: 0.9804\n",
      "Epoch 566/1000\n",
      "202/202 [==============================] - 0s 94us/step - loss: 4.8654e-04 - accuracy: 1.0000 - val_loss: 0.2164 - val_accuracy: 0.9804\n",
      "Epoch 567/1000\n",
      "202/202 [==============================] - 0s 93us/step - loss: 4.9740e-04 - accuracy: 1.0000 - val_loss: 0.2182 - val_accuracy: 0.9804\n",
      "Epoch 568/1000\n",
      "202/202 [==============================] - 0s 76us/step - loss: 4.7854e-04 - accuracy: 1.0000 - val_loss: 0.2106 - val_accuracy: 0.9804\n",
      "Epoch 569/1000\n",
      "202/202 [==============================] - 0s 90us/step - loss: 4.9003e-04 - accuracy: 1.0000 - val_loss: 0.2129 - val_accuracy: 0.9804\n",
      "Epoch 570/1000\n",
      "202/202 [==============================] - 0s 83us/step - loss: 4.9236e-04 - accuracy: 1.0000 - val_loss: 0.2177 - val_accuracy: 0.9804\n",
      "Epoch 571/1000\n",
      "202/202 [==============================] - 0s 83us/step - loss: 4.9098e-04 - accuracy: 1.0000 - val_loss: 0.2140 - val_accuracy: 0.9804\n",
      "Epoch 572/1000\n",
      "202/202 [==============================] - 0s 106us/step - loss: 4.8743e-04 - accuracy: 1.0000 - val_loss: 0.2148 - val_accuracy: 0.9804\n",
      "Epoch 573/1000\n",
      "202/202 [==============================] - 0s 71us/step - loss: 4.8544e-04 - accuracy: 1.0000 - val_loss: 0.2141 - val_accuracy: 0.9804\n",
      "Epoch 574/1000\n",
      "202/202 [==============================] - 0s 109us/step - loss: 4.7621e-04 - accuracy: 1.0000 - val_loss: 0.2181 - val_accuracy: 0.9804\n",
      "Epoch 575/1000\n",
      "202/202 [==============================] - 0s 94us/step - loss: 5.2340e-04 - accuracy: 1.0000 - val_loss: 0.2248 - val_accuracy: 0.9804\n",
      "Epoch 576/1000\n",
      "202/202 [==============================] - 0s 98us/step - loss: 4.7533e-04 - accuracy: 1.0000 - val_loss: 0.2141 - val_accuracy: 0.9804\n",
      "Epoch 577/1000\n",
      "202/202 [==============================] - 0s 98us/step - loss: 4.7259e-04 - accuracy: 1.0000 - val_loss: 0.2141 - val_accuracy: 0.9804\n",
      "Epoch 578/1000\n",
      "202/202 [==============================] - 0s 84us/step - loss: 4.6865e-04 - accuracy: 1.0000 - val_loss: 0.2132 - val_accuracy: 0.9804\n",
      "Epoch 579/1000\n",
      "202/202 [==============================] - 0s 90us/step - loss: 4.6292e-04 - accuracy: 1.0000 - val_loss: 0.2191 - val_accuracy: 0.9804\n",
      "Epoch 580/1000\n",
      "202/202 [==============================] - 0s 91us/step - loss: 4.7702e-04 - accuracy: 1.0000 - val_loss: 0.2231 - val_accuracy: 0.9804\n",
      "Epoch 581/1000\n",
      "202/202 [==============================] - 0s 86us/step - loss: 4.8179e-04 - accuracy: 1.0000 - val_loss: 0.2222 - val_accuracy: 0.9804\n",
      "Epoch 582/1000\n",
      "202/202 [==============================] - 0s 92us/step - loss: 4.5403e-04 - accuracy: 1.0000 - val_loss: 0.2174 - val_accuracy: 0.9804\n",
      "Epoch 583/1000\n",
      "202/202 [==============================] - 0s 96us/step - loss: 4.7108e-04 - accuracy: 1.0000 - val_loss: 0.2169 - val_accuracy: 0.9804\n",
      "Epoch 584/1000\n",
      "202/202 [==============================] - 0s 95us/step - loss: 4.5660e-04 - accuracy: 1.0000 - val_loss: 0.2179 - val_accuracy: 0.9804\n",
      "Epoch 585/1000\n",
      "202/202 [==============================] - 0s 82us/step - loss: 4.7837e-04 - accuracy: 1.0000 - val_loss: 0.2148 - val_accuracy: 0.9804\n",
      "Epoch 586/1000\n",
      "202/202 [==============================] - 0s 91us/step - loss: 4.7264e-04 - accuracy: 1.0000 - val_loss: 0.2259 - val_accuracy: 0.9804\n",
      "Epoch 587/1000\n",
      "202/202 [==============================] - 0s 92us/step - loss: 4.6758e-04 - accuracy: 1.0000 - val_loss: 0.2227 - val_accuracy: 0.9804\n",
      "Epoch 588/1000\n",
      "202/202 [==============================] - 0s 95us/step - loss: 4.6967e-04 - accuracy: 1.0000 - val_loss: 0.2150 - val_accuracy: 0.9804\n",
      "Epoch 589/1000\n",
      "202/202 [==============================] - 0s 86us/step - loss: 4.4322e-04 - accuracy: 1.0000 - val_loss: 0.2177 - val_accuracy: 0.9804\n",
      "Epoch 590/1000\n",
      "202/202 [==============================] - 0s 83us/step - loss: 4.6403e-04 - accuracy: 1.0000 - val_loss: 0.2231 - val_accuracy: 0.9804\n",
      "Epoch 591/1000\n",
      "202/202 [==============================] - 0s 98us/step - loss: 4.4298e-04 - accuracy: 1.0000 - val_loss: 0.2170 - val_accuracy: 0.9804\n",
      "Epoch 592/1000\n",
      "202/202 [==============================] - 0s 85us/step - loss: 4.3637e-04 - accuracy: 1.0000 - val_loss: 0.2168 - val_accuracy: 0.9804\n",
      "Epoch 593/1000\n",
      "202/202 [==============================] - 0s 85us/step - loss: 4.5219e-04 - accuracy: 1.0000 - val_loss: 0.2211 - val_accuracy: 0.9804\n",
      "Epoch 594/1000\n",
      "202/202 [==============================] - 0s 100us/step - loss: 4.3787e-04 - accuracy: 1.0000 - val_loss: 0.2196 - val_accuracy: 0.9804\n",
      "Epoch 595/1000\n",
      "202/202 [==============================] - 0s 91us/step - loss: 4.4272e-04 - accuracy: 1.0000 - val_loss: 0.2187 - val_accuracy: 0.9804\n",
      "Epoch 596/1000\n",
      "202/202 [==============================] - 0s 95us/step - loss: 4.1137e-04 - accuracy: 1.0000 - val_loss: 0.2280 - val_accuracy: 0.9804\n",
      "Epoch 597/1000\n",
      "202/202 [==============================] - 0s 105us/step - loss: 4.4361e-04 - accuracy: 1.0000 - val_loss: 0.2272 - val_accuracy: 0.9804\n",
      "Epoch 598/1000\n",
      "202/202 [==============================] - 0s 96us/step - loss: 4.3370e-04 - accuracy: 1.0000 - val_loss: 0.2228 - val_accuracy: 0.9804\n",
      "Epoch 599/1000\n",
      "202/202 [==============================] - 0s 100us/step - loss: 4.1982e-04 - accuracy: 1.0000 - val_loss: 0.2215 - val_accuracy: 0.9804\n",
      "Epoch 600/1000\n",
      "202/202 [==============================] - 0s 97us/step - loss: 4.2060e-04 - accuracy: 1.0000 - val_loss: 0.2195 - val_accuracy: 0.9804\n",
      "Epoch 601/1000\n",
      "202/202 [==============================] - 0s 94us/step - loss: 4.2611e-04 - accuracy: 1.0000 - val_loss: 0.2130 - val_accuracy: 0.9804\n",
      "Epoch 602/1000\n",
      "202/202 [==============================] - 0s 87us/step - loss: 4.6157e-04 - accuracy: 1.0000 - val_loss: 0.2143 - val_accuracy: 0.9804\n",
      "Epoch 603/1000\n",
      "202/202 [==============================] - 0s 114us/step - loss: 4.3947e-04 - accuracy: 1.0000 - val_loss: 0.2286 - val_accuracy: 0.9804\n",
      "Epoch 604/1000\n",
      "202/202 [==============================] - 0s 105us/step - loss: 4.2726e-04 - accuracy: 1.0000 - val_loss: 0.2274 - val_accuracy: 0.9804\n",
      "Epoch 605/1000\n",
      "202/202 [==============================] - 0s 100us/step - loss: 4.1253e-04 - accuracy: 1.0000 - val_loss: 0.2223 - val_accuracy: 0.9804\n",
      "Epoch 606/1000\n",
      "202/202 [==============================] - 0s 111us/step - loss: 4.2060e-04 - accuracy: 1.0000 - val_loss: 0.2243 - val_accuracy: 0.9804\n",
      "Epoch 607/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202/202 [==============================] - 0s 96us/step - loss: 4.2036e-04 - accuracy: 1.0000 - val_loss: 0.2258 - val_accuracy: 0.9804\n",
      "Epoch 608/1000\n",
      "202/202 [==============================] - 0s 96us/step - loss: 4.4550e-04 - accuracy: 1.0000 - val_loss: 0.2272 - val_accuracy: 0.9804\n",
      "Epoch 609/1000\n",
      "202/202 [==============================] - 0s 88us/step - loss: 4.1442e-04 - accuracy: 1.0000 - val_loss: 0.2222 - val_accuracy: 0.9804\n",
      "Epoch 610/1000\n",
      "202/202 [==============================] - 0s 92us/step - loss: 4.1025e-04 - accuracy: 1.0000 - val_loss: 0.2204 - val_accuracy: 0.9804\n",
      "Epoch 611/1000\n",
      "202/202 [==============================] - 0s 106us/step - loss: 4.1221e-04 - accuracy: 1.0000 - val_loss: 0.2303 - val_accuracy: 0.9804\n",
      "Epoch 612/1000\n",
      "202/202 [==============================] - 0s 90us/step - loss: 4.0950e-04 - accuracy: 1.0000 - val_loss: 0.2285 - val_accuracy: 0.9804\n",
      "Epoch 613/1000\n",
      "202/202 [==============================] - 0s 112us/step - loss: 4.1615e-04 - accuracy: 1.0000 - val_loss: 0.2217 - val_accuracy: 0.9804\n",
      "Epoch 614/1000\n",
      "202/202 [==============================] - 0s 87us/step - loss: 3.9884e-04 - accuracy: 1.0000 - val_loss: 0.2248 - val_accuracy: 0.9804\n",
      "Epoch 615/1000\n",
      "202/202 [==============================] - 0s 117us/step - loss: 3.9292e-04 - accuracy: 1.0000 - val_loss: 0.2289 - val_accuracy: 0.9804\n",
      "Epoch 616/1000\n",
      "202/202 [==============================] - 0s 75us/step - loss: 4.0204e-04 - accuracy: 1.0000 - val_loss: 0.2293 - val_accuracy: 0.9804\n",
      "Epoch 617/1000\n",
      "202/202 [==============================] - 0s 84us/step - loss: 4.1377e-04 - accuracy: 1.0000 - val_loss: 0.2216 - val_accuracy: 0.9804\n",
      "Epoch 618/1000\n",
      "202/202 [==============================] - 0s 96us/step - loss: 3.8122e-04 - accuracy: 1.0000 - val_loss: 0.2317 - val_accuracy: 0.9804\n",
      "Epoch 619/1000\n",
      "202/202 [==============================] - 0s 98us/step - loss: 4.1405e-04 - accuracy: 1.0000 - val_loss: 0.2328 - val_accuracy: 0.9804\n",
      "Epoch 620/1000\n",
      "202/202 [==============================] - 0s 88us/step - loss: 4.1673e-04 - accuracy: 1.0000 - val_loss: 0.2314 - val_accuracy: 0.9804\n",
      "Epoch 621/1000\n",
      "202/202 [==============================] - 0s 94us/step - loss: 3.8543e-04 - accuracy: 1.0000 - val_loss: 0.2218 - val_accuracy: 0.9804\n",
      "Epoch 622/1000\n",
      "202/202 [==============================] - 0s 83us/step - loss: 3.9496e-04 - accuracy: 1.0000 - val_loss: 0.2241 - val_accuracy: 0.9804\n",
      "Epoch 623/1000\n",
      "202/202 [==============================] - 0s 83us/step - loss: 3.7838e-04 - accuracy: 1.0000 - val_loss: 0.2369 - val_accuracy: 0.9804\n",
      "Epoch 624/1000\n",
      "202/202 [==============================] - 0s 97us/step - loss: 3.9711e-04 - accuracy: 1.0000 - val_loss: 0.2318 - val_accuracy: 0.9804\n",
      "Epoch 625/1000\n",
      "202/202 [==============================] - 0s 83us/step - loss: 3.9954e-04 - accuracy: 1.0000 - val_loss: 0.2162 - val_accuracy: 0.9804\n",
      "Epoch 626/1000\n",
      "202/202 [==============================] - 0s 103us/step - loss: 4.1490e-04 - accuracy: 1.0000 - val_loss: 0.2223 - val_accuracy: 0.9804\n",
      "Epoch 627/1000\n",
      "202/202 [==============================] - 0s 93us/step - loss: 4.1198e-04 - accuracy: 1.0000 - val_loss: 0.2381 - val_accuracy: 0.9804\n",
      "Epoch 628/1000\n",
      "202/202 [==============================] - 0s 92us/step - loss: 3.5554e-04 - accuracy: 1.0000 - val_loss: 0.2207 - val_accuracy: 0.9804\n",
      "Epoch 629/1000\n",
      "202/202 [==============================] - 0s 90us/step - loss: 4.3327e-04 - accuracy: 1.0000 - val_loss: 0.2191 - val_accuracy: 0.9804\n",
      "Epoch 630/1000\n",
      "202/202 [==============================] - 0s 93us/step - loss: 3.5645e-04 - accuracy: 1.0000 - val_loss: 0.2391 - val_accuracy: 0.9804\n",
      "Epoch 631/1000\n",
      "202/202 [==============================] - 0s 90us/step - loss: 3.9912e-04 - accuracy: 1.0000 - val_loss: 0.2398 - val_accuracy: 0.9804\n",
      "Epoch 632/1000\n",
      "202/202 [==============================] - 0s 93us/step - loss: 3.9241e-04 - accuracy: 1.0000 - val_loss: 0.2286 - val_accuracy: 0.9804\n",
      "Epoch 633/1000\n",
      "202/202 [==============================] - 0s 96us/step - loss: 3.6023e-04 - accuracy: 1.0000 - val_loss: 0.2284 - val_accuracy: 0.9804\n",
      "Epoch 634/1000\n",
      "202/202 [==============================] - ETA: 0s - loss: 1.5240e-04 - accuracy: 1.00 - 0s 158us/step - loss: 3.5649e-04 - accuracy: 1.0000 - val_loss: 0.2266 - val_accuracy: 0.9804\n",
      "Epoch 635/1000\n",
      "202/202 [==============================] - 0s 108us/step - loss: 3.5964e-04 - accuracy: 1.0000 - val_loss: 0.2275 - val_accuracy: 0.9804\n",
      "Epoch 636/1000\n",
      "202/202 [==============================] - 0s 95us/step - loss: 3.8775e-04 - accuracy: 1.0000 - val_loss: 0.2353 - val_accuracy: 0.9804\n",
      "Epoch 637/1000\n",
      "202/202 [==============================] - 0s 130us/step - loss: 3.6355e-04 - accuracy: 1.0000 - val_loss: 0.2260 - val_accuracy: 0.9804\n",
      "Epoch 638/1000\n",
      "202/202 [==============================] - 0s 76us/step - loss: 3.5545e-04 - accuracy: 1.0000 - val_loss: 0.2284 - val_accuracy: 0.9804\n",
      "Epoch 639/1000\n",
      "202/202 [==============================] - 0s 101us/step - loss: 3.5115e-04 - accuracy: 1.0000 - val_loss: 0.2311 - val_accuracy: 0.9804\n",
      "Epoch 640/1000\n",
      "202/202 [==============================] - 0s 99us/step - loss: 3.4798e-04 - accuracy: 1.0000 - val_loss: 0.2295 - val_accuracy: 0.9804\n",
      "Epoch 641/1000\n",
      "202/202 [==============================] - 0s 91us/step - loss: 3.5272e-04 - accuracy: 1.0000 - val_loss: 0.2284 - val_accuracy: 0.9804\n",
      "Epoch 642/1000\n",
      "202/202 [==============================] - 0s 90us/step - loss: 3.5605e-04 - accuracy: 1.0000 - val_loss: 0.2262 - val_accuracy: 0.9804\n",
      "Epoch 643/1000\n",
      "202/202 [==============================] - 0s 92us/step - loss: 3.7692e-04 - accuracy: 1.0000 - val_loss: 0.2212 - val_accuracy: 0.9804\n",
      "Epoch 644/1000\n",
      "202/202 [==============================] - 0s 97us/step - loss: 3.6487e-04 - accuracy: 1.0000 - val_loss: 0.2345 - val_accuracy: 0.9804\n",
      "Epoch 645/1000\n",
      "202/202 [==============================] - 0s 93us/step - loss: 3.3863e-04 - accuracy: 1.0000 - val_loss: 0.2358 - val_accuracy: 0.9804\n",
      "Epoch 646/1000\n",
      "202/202 [==============================] - 0s 76us/step - loss: 3.4718e-04 - accuracy: 1.0000 - val_loss: 0.2326 - val_accuracy: 0.9804\n",
      "Epoch 647/1000\n",
      "202/202 [==============================] - 0s 95us/step - loss: 3.4310e-04 - accuracy: 1.0000 - val_loss: 0.2338 - val_accuracy: 0.9804\n",
      "Epoch 648/1000\n",
      "202/202 [==============================] - 0s 88us/step - loss: 3.3498e-04 - accuracy: 1.0000 - val_loss: 0.2272 - val_accuracy: 0.9804\n",
      "Epoch 649/1000\n",
      "202/202 [==============================] - 0s 108us/step - loss: 3.4720e-04 - accuracy: 1.0000 - val_loss: 0.2329 - val_accuracy: 0.9804\n",
      "Epoch 650/1000\n",
      "202/202 [==============================] - 0s 88us/step - loss: 3.3568e-04 - accuracy: 1.0000 - val_loss: 0.2335 - val_accuracy: 0.9804\n",
      "Epoch 651/1000\n",
      "202/202 [==============================] - 0s 82us/step - loss: 3.4913e-04 - accuracy: 1.0000 - val_loss: 0.2311 - val_accuracy: 0.9804\n",
      "Epoch 652/1000\n",
      "202/202 [==============================] - 0s 70us/step - loss: 3.3978e-04 - accuracy: 1.0000 - val_loss: 0.2397 - val_accuracy: 0.9804\n",
      "Epoch 653/1000\n",
      "202/202 [==============================] - 0s 93us/step - loss: 3.5561e-04 - accuracy: 1.0000 - val_loss: 0.2398 - val_accuracy: 0.9804\n",
      "Epoch 654/1000\n",
      "202/202 [==============================] - 0s 88us/step - loss: 3.3146e-04 - accuracy: 1.0000 - val_loss: 0.2322 - val_accuracy: 0.9804\n",
      "Epoch 655/1000\n",
      "202/202 [==============================] - 0s 108us/step - loss: 3.3269e-04 - accuracy: 1.0000 - val_loss: 0.2297 - val_accuracy: 0.9804\n",
      "Epoch 656/1000\n",
      "202/202 [==============================] - 0s 103us/step - loss: 3.4583e-04 - accuracy: 1.0000 - val_loss: 0.2269 - val_accuracy: 0.9804\n",
      "Epoch 657/1000\n",
      "202/202 [==============================] - 0s 88us/step - loss: 3.4587e-04 - accuracy: 1.0000 - val_loss: 0.2337 - val_accuracy: 0.9804\n",
      "Epoch 658/1000\n",
      "202/202 [==============================] - 0s 94us/step - loss: 3.5774e-04 - accuracy: 1.0000 - val_loss: 0.2405 - val_accuracy: 0.9804\n",
      "Epoch 659/1000\n",
      "202/202 [==============================] - 0s 128us/step - loss: 3.2123e-04 - accuracy: 1.0000 - val_loss: 0.2349 - val_accuracy: 0.9804\n",
      "Epoch 660/1000\n",
      "202/202 [==============================] - 0s 102us/step - loss: 3.3532e-04 - accuracy: 1.0000 - val_loss: 0.2271 - val_accuracy: 0.9804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 661/1000\n",
      "202/202 [==============================] - 0s 87us/step - loss: 3.3079e-04 - accuracy: 1.0000 - val_loss: 0.2372 - val_accuracy: 0.9804\n",
      "Epoch 662/1000\n",
      "202/202 [==============================] - 0s 95us/step - loss: 3.2028e-04 - accuracy: 1.0000 - val_loss: 0.2379 - val_accuracy: 0.9804\n",
      "Epoch 663/1000\n",
      "202/202 [==============================] - 0s 92us/step - loss: 3.1748e-04 - accuracy: 1.0000 - val_loss: 0.2356 - val_accuracy: 0.9804\n",
      "Epoch 664/1000\n",
      "202/202 [==============================] - 0s 99us/step - loss: 3.2055e-04 - accuracy: 1.0000 - val_loss: 0.2317 - val_accuracy: 0.9804\n",
      "Epoch 665/1000\n",
      "202/202 [==============================] - 0s 92us/step - loss: 3.2348e-04 - accuracy: 1.0000 - val_loss: 0.2322 - val_accuracy: 0.9804\n",
      "Epoch 666/1000\n",
      "202/202 [==============================] - 0s 85us/step - loss: 3.1686e-04 - accuracy: 1.0000 - val_loss: 0.2353 - val_accuracy: 0.9804\n",
      "Epoch 667/1000\n",
      "202/202 [==============================] - 0s 84us/step - loss: 3.2591e-04 - accuracy: 1.0000 - val_loss: 0.2267 - val_accuracy: 0.9804\n",
      "Epoch 668/1000\n",
      "202/202 [==============================] - 0s 94us/step - loss: 3.1648e-04 - accuracy: 1.0000 - val_loss: 0.2382 - val_accuracy: 0.9804\n",
      "Epoch 669/1000\n",
      "202/202 [==============================] - 0s 104us/step - loss: 3.1167e-04 - accuracy: 1.0000 - val_loss: 0.2381 - val_accuracy: 0.9804\n",
      "Epoch 670/1000\n",
      "202/202 [==============================] - 0s 83us/step - loss: 3.1991e-04 - accuracy: 1.0000 - val_loss: 0.2435 - val_accuracy: 0.9804\n",
      "Epoch 671/1000\n",
      "202/202 [==============================] - 0s 80us/step - loss: 3.1724e-04 - accuracy: 1.0000 - val_loss: 0.2325 - val_accuracy: 0.9804\n",
      "Epoch 672/1000\n",
      "202/202 [==============================] - 0s 93us/step - loss: 3.0351e-04 - accuracy: 1.0000 - val_loss: 0.2320 - val_accuracy: 0.9804\n",
      "Epoch 673/1000\n",
      "202/202 [==============================] - 0s 94us/step - loss: 3.1690e-04 - accuracy: 1.0000 - val_loss: 0.2308 - val_accuracy: 0.9804\n",
      "Epoch 674/1000\n",
      "202/202 [==============================] - 0s 114us/step - loss: 3.2501e-04 - accuracy: 1.0000 - val_loss: 0.2416 - val_accuracy: 0.9804\n",
      "Epoch 675/1000\n",
      "202/202 [==============================] - 0s 97us/step - loss: 2.9911e-04 - accuracy: 1.0000 - val_loss: 0.2377 - val_accuracy: 0.9804\n",
      "Epoch 676/1000\n",
      "202/202 [==============================] - 0s 98us/step - loss: 2.9587e-04 - accuracy: 1.0000 - val_loss: 0.2351 - val_accuracy: 0.9804\n",
      "Epoch 677/1000\n",
      "202/202 [==============================] - 0s 90us/step - loss: 3.0218e-04 - accuracy: 1.0000 - val_loss: 0.2334 - val_accuracy: 0.9804\n",
      "Epoch 678/1000\n",
      "202/202 [==============================] - 0s 86us/step - loss: 2.9598e-04 - accuracy: 1.0000 - val_loss: 0.2385 - val_accuracy: 0.9804\n",
      "Epoch 679/1000\n",
      "202/202 [==============================] - 0s 96us/step - loss: 2.9148e-04 - accuracy: 1.0000 - val_loss: 0.2334 - val_accuracy: 0.9804\n",
      "Epoch 680/1000\n",
      "202/202 [==============================] - 0s 80us/step - loss: 2.9936e-04 - accuracy: 1.0000 - val_loss: 0.2336 - val_accuracy: 0.9804\n",
      "Epoch 681/1000\n",
      "202/202 [==============================] - 0s 78us/step - loss: 2.8943e-04 - accuracy: 1.0000 - val_loss: 0.2399 - val_accuracy: 0.9804\n",
      "Epoch 682/1000\n",
      "202/202 [==============================] - 0s 91us/step - loss: 2.9473e-04 - accuracy: 1.0000 - val_loss: 0.2481 - val_accuracy: 0.9804\n",
      "Epoch 683/1000\n",
      "202/202 [==============================] - 0s 93us/step - loss: 3.0875e-04 - accuracy: 1.0000 - val_loss: 0.2389 - val_accuracy: 0.9804\n",
      "Epoch 684/1000\n",
      "202/202 [==============================] - 0s 88us/step - loss: 2.8812e-04 - accuracy: 1.0000 - val_loss: 0.2374 - val_accuracy: 0.9804\n",
      "Epoch 685/1000\n",
      "202/202 [==============================] - 0s 93us/step - loss: 2.9070e-04 - accuracy: 1.0000 - val_loss: 0.2383 - val_accuracy: 0.9804\n",
      "Epoch 686/1000\n",
      "202/202 [==============================] - 0s 88us/step - loss: 2.8578e-04 - accuracy: 1.0000 - val_loss: 0.2370 - val_accuracy: 0.9804\n",
      "Epoch 687/1000\n",
      "202/202 [==============================] - 0s 114us/step - loss: 2.9405e-04 - accuracy: 1.0000 - val_loss: 0.2450 - val_accuracy: 0.9804\n",
      "Epoch 688/1000\n",
      "202/202 [==============================] - 0s 96us/step - loss: 2.7216e-04 - accuracy: 1.0000 - val_loss: 0.2361 - val_accuracy: 0.9804\n",
      "Epoch 689/1000\n",
      "202/202 [==============================] - 0s 91us/step - loss: 2.8708e-04 - accuracy: 1.0000 - val_loss: 0.2411 - val_accuracy: 0.9804\n",
      "Epoch 690/1000\n",
      "202/202 [==============================] - 0s 90us/step - loss: 2.8422e-04 - accuracy: 1.0000 - val_loss: 0.2408 - val_accuracy: 0.9804\n",
      "Epoch 691/1000\n",
      "202/202 [==============================] - 0s 80us/step - loss: 2.7996e-04 - accuracy: 1.0000 - val_loss: 0.2374 - val_accuracy: 0.9804\n",
      "Epoch 692/1000\n",
      "202/202 [==============================] - 0s 111us/step - loss: 2.7725e-04 - accuracy: 1.0000 - val_loss: 0.2392 - val_accuracy: 0.9804\n",
      "Epoch 693/1000\n",
      "202/202 [==============================] - 0s 104us/step - loss: 2.7814e-04 - accuracy: 1.0000 - val_loss: 0.2444 - val_accuracy: 0.9804\n",
      "Epoch 694/1000\n",
      "202/202 [==============================] - 0s 87us/step - loss: 3.0544e-04 - accuracy: 1.0000 - val_loss: 0.2489 - val_accuracy: 0.9804\n",
      "Epoch 695/1000\n",
      "202/202 [==============================] - 0s 89us/step - loss: 2.6961e-04 - accuracy: 1.0000 - val_loss: 0.2389 - val_accuracy: 0.9804\n",
      "Epoch 696/1000\n",
      "202/202 [==============================] - 0s 87us/step - loss: 2.7693e-04 - accuracy: 1.0000 - val_loss: 0.2361 - val_accuracy: 0.9804\n",
      "Epoch 697/1000\n",
      "202/202 [==============================] - 0s 87us/step - loss: 2.7435e-04 - accuracy: 1.0000 - val_loss: 0.2423 - val_accuracy: 0.9804\n",
      "Epoch 698/1000\n",
      "202/202 [==============================] - 0s 82us/step - loss: 2.7331e-04 - accuracy: 1.0000 - val_loss: 0.2426 - val_accuracy: 0.9804\n",
      "Epoch 699/1000\n",
      "202/202 [==============================] - 0s 87us/step - loss: 2.8695e-04 - accuracy: 1.0000 - val_loss: 0.2340 - val_accuracy: 0.9804\n",
      "Epoch 700/1000\n",
      "202/202 [==============================] - 0s 88us/step - loss: 2.6443e-04 - accuracy: 1.0000 - val_loss: 0.2468 - val_accuracy: 0.9804\n",
      "Epoch 701/1000\n",
      "202/202 [==============================] - 0s 80us/step - loss: 2.7775e-04 - accuracy: 1.0000 - val_loss: 0.2485 - val_accuracy: 0.9804\n",
      "Epoch 702/1000\n",
      "202/202 [==============================] - 0s 92us/step - loss: 2.8081e-04 - accuracy: 1.0000 - val_loss: 0.2418 - val_accuracy: 0.9804\n",
      "Epoch 703/1000\n",
      "202/202 [==============================] - 0s 85us/step - loss: 2.6230e-04 - accuracy: 1.0000 - val_loss: 0.2427 - val_accuracy: 0.9804\n",
      "Epoch 704/1000\n",
      "202/202 [==============================] - 0s 87us/step - loss: 2.6012e-04 - accuracy: 1.0000 - val_loss: 0.2455 - val_accuracy: 0.9804\n",
      "Epoch 705/1000\n",
      "202/202 [==============================] - 0s 96us/step - loss: 2.6959e-04 - accuracy: 1.0000 - val_loss: 0.2467 - val_accuracy: 0.9804\n",
      "Epoch 706/1000\n",
      "202/202 [==============================] - 0s 82us/step - loss: 2.7990e-04 - accuracy: 1.0000 - val_loss: 0.2322 - val_accuracy: 0.9804\n",
      "Epoch 707/1000\n",
      "202/202 [==============================] - 0s 92us/step - loss: 2.8138e-04 - accuracy: 1.0000 - val_loss: 0.2399 - val_accuracy: 0.9804\n",
      "Epoch 708/1000\n",
      "202/202 [==============================] - 0s 96us/step - loss: 2.6009e-04 - accuracy: 1.0000 - val_loss: 0.2423 - val_accuracy: 0.9804\n",
      "Epoch 709/1000\n",
      "202/202 [==============================] - 0s 105us/step - loss: 2.6026e-04 - accuracy: 1.0000 - val_loss: 0.2430 - val_accuracy: 0.9804\n",
      "Epoch 710/1000\n",
      "202/202 [==============================] - 0s 101us/step - loss: 2.6745e-04 - accuracy: 1.0000 - val_loss: 0.2511 - val_accuracy: 0.9804\n",
      "Epoch 711/1000\n",
      "202/202 [==============================] - 0s 80us/step - loss: 2.6536e-04 - accuracy: 1.0000 - val_loss: 0.2464 - val_accuracy: 0.9804\n",
      "Epoch 712/1000\n",
      "202/202 [==============================] - 0s 92us/step - loss: 2.6042e-04 - accuracy: 1.0000 - val_loss: 0.2396 - val_accuracy: 0.9804\n",
      "Epoch 713/1000\n",
      "202/202 [==============================] - 0s 83us/step - loss: 2.5196e-04 - accuracy: 1.0000 - val_loss: 0.2480 - val_accuracy: 0.9804\n",
      "Epoch 714/1000\n",
      "202/202 [==============================] - 0s 80us/step - loss: 2.8305e-04 - accuracy: 1.0000 - val_loss: 0.2530 - val_accuracy: 0.9804\n",
      "Epoch 715/1000\n",
      "202/202 [==============================] - 0s 94us/step - loss: 2.6109e-04 - accuracy: 1.0000 - val_loss: 0.2459 - val_accuracy: 0.9804\n",
      "Epoch 716/1000\n",
      "202/202 [==============================] - 0s 86us/step - loss: 2.4451e-04 - accuracy: 1.0000 - val_loss: 0.2374 - val_accuracy: 0.9804\n",
      "Epoch 717/1000\n",
      "202/202 [==============================] - 0s 89us/step - loss: 2.5558e-04 - accuracy: 1.0000 - val_loss: 0.2412 - val_accuracy: 0.9804\n",
      "Epoch 718/1000\n",
      "202/202 [==============================] - 0s 85us/step - loss: 2.4463e-04 - accuracy: 1.0000 - val_loss: 0.2461 - val_accuracy: 0.9804\n",
      "Epoch 719/1000\n",
      "202/202 [==============================] - 0s 82us/step - loss: 2.4369e-04 - accuracy: 1.0000 - val_loss: 0.2473 - val_accuracy: 0.9804\n",
      "Epoch 720/1000\n",
      "202/202 [==============================] - 0s 95us/step - loss: 2.4640e-04 - accuracy: 1.0000 - val_loss: 0.2478 - val_accuracy: 0.9804\n",
      "Epoch 721/1000\n",
      "202/202 [==============================] - 0s 92us/step - loss: 2.4390e-04 - accuracy: 1.0000 - val_loss: 0.2456 - val_accuracy: 0.9804\n",
      "Epoch 722/1000\n",
      "202/202 [==============================] - 0s 83us/step - loss: 2.4210e-04 - accuracy: 1.0000 - val_loss: 0.2444 - val_accuracy: 0.9804\n",
      "Epoch 723/1000\n",
      "202/202 [==============================] - 0s 86us/step - loss: 2.4357e-04 - accuracy: 1.0000 - val_loss: 0.2453 - val_accuracy: 0.9804\n",
      "Epoch 724/1000\n",
      "202/202 [==============================] - 0s 83us/step - loss: 2.3866e-04 - accuracy: 1.0000 - val_loss: 0.2530 - val_accuracy: 0.9804\n",
      "Epoch 725/1000\n",
      "202/202 [==============================] - 0s 86us/step - loss: 2.4201e-04 - accuracy: 1.0000 - val_loss: 0.2489 - val_accuracy: 0.9804\n",
      "Epoch 726/1000\n",
      "202/202 [==============================] - 0s 115us/step - loss: 2.5010e-04 - accuracy: 1.0000 - val_loss: 0.2440 - val_accuracy: 0.9804\n",
      "Epoch 727/1000\n",
      "202/202 [==============================] - 0s 89us/step - loss: 2.4233e-04 - accuracy: 1.0000 - val_loss: 0.2473 - val_accuracy: 0.9804\n",
      "Epoch 728/1000\n",
      "202/202 [==============================] - 0s 73us/step - loss: 2.4617e-04 - accuracy: 1.0000 - val_loss: 0.2508 - val_accuracy: 0.9804\n",
      "Epoch 729/1000\n",
      "202/202 [==============================] - 0s 88us/step - loss: 2.4071e-04 - accuracy: 1.0000 - val_loss: 0.2433 - val_accuracy: 0.9804\n",
      "Epoch 730/1000\n",
      "202/202 [==============================] - 0s 88us/step - loss: 2.3225e-04 - accuracy: 1.0000 - val_loss: 0.2464 - val_accuracy: 0.9804\n",
      "Epoch 731/1000\n",
      "202/202 [==============================] - 0s 107us/step - loss: 2.3015e-04 - accuracy: 1.0000 - val_loss: 0.2524 - val_accuracy: 0.9804\n",
      "Epoch 732/1000\n",
      "202/202 [==============================] - 0s 76us/step - loss: 2.3843e-04 - accuracy: 1.0000 - val_loss: 0.2495 - val_accuracy: 0.9804\n",
      "Epoch 733/1000\n",
      "202/202 [==============================] - 0s 82us/step - loss: 2.2425e-04 - accuracy: 1.0000 - val_loss: 0.2399 - val_accuracy: 0.9804\n",
      "Epoch 734/1000\n",
      "202/202 [==============================] - 0s 97us/step - loss: 2.4060e-04 - accuracy: 1.0000 - val_loss: 0.2442 - val_accuracy: 0.9804\n",
      "Epoch 735/1000\n",
      "202/202 [==============================] - 0s 102us/step - loss: 2.5288e-04 - accuracy: 1.0000 - val_loss: 0.2528 - val_accuracy: 0.9804\n",
      "Epoch 736/1000\n",
      "202/202 [==============================] - 0s 85us/step - loss: 2.7582e-04 - accuracy: 1.0000 - val_loss: 0.2346 - val_accuracy: 0.9804\n",
      "Epoch 737/1000\n",
      "202/202 [==============================] - 0s 130us/step - loss: 2.3148e-04 - accuracy: 1.0000 - val_loss: 0.2585 - val_accuracy: 0.9804\n",
      "Epoch 738/1000\n",
      "202/202 [==============================] - 0s 104us/step - loss: 2.3734e-04 - accuracy: 1.0000 - val_loss: 0.2612 - val_accuracy: 0.9804\n",
      "Epoch 739/1000\n",
      "202/202 [==============================] - 0s 89us/step - loss: 2.4287e-04 - accuracy: 1.0000 - val_loss: 0.2487 - val_accuracy: 0.9804\n",
      "Epoch 740/1000\n",
      "202/202 [==============================] - 0s 106us/step - loss: 2.2171e-04 - accuracy: 1.0000 - val_loss: 0.2467 - val_accuracy: 0.9804\n",
      "Epoch 741/1000\n",
      "202/202 [==============================] - 0s 97us/step - loss: 2.2618e-04 - accuracy: 1.0000 - val_loss: 0.2469 - val_accuracy: 0.9804\n",
      "Epoch 742/1000\n",
      "202/202 [==============================] - 0s 82us/step - loss: 2.2408e-04 - accuracy: 1.0000 - val_loss: 0.2535 - val_accuracy: 0.9804\n",
      "Epoch 743/1000\n",
      "202/202 [==============================] - 0s 99us/step - loss: 2.2126e-04 - accuracy: 1.0000 - val_loss: 0.2552 - val_accuracy: 0.9804\n",
      "Epoch 744/1000\n",
      "202/202 [==============================] - 0s 106us/step - loss: 2.2544e-04 - accuracy: 1.0000 - val_loss: 0.2514 - val_accuracy: 0.9804\n",
      "Epoch 745/1000\n",
      "202/202 [==============================] - 0s 98us/step - loss: 2.3337e-04 - accuracy: 1.0000 - val_loss: 0.2374 - val_accuracy: 0.9804\n",
      "Epoch 746/1000\n",
      "202/202 [==============================] - 0s 86us/step - loss: 2.5372e-04 - accuracy: 1.0000 - val_loss: 0.2501 - val_accuracy: 0.9804\n",
      "Epoch 747/1000\n",
      "202/202 [==============================] - 0s 84us/step - loss: 2.1915e-04 - accuracy: 1.0000 - val_loss: 0.2566 - val_accuracy: 0.9804\n",
      "Epoch 748/1000\n",
      "202/202 [==============================] - 0s 86us/step - loss: 2.2234e-04 - accuracy: 1.0000 - val_loss: 0.2551 - val_accuracy: 0.9804\n",
      "Epoch 749/1000\n",
      "202/202 [==============================] - 0s 95us/step - loss: 2.1719e-04 - accuracy: 1.0000 - val_loss: 0.2527 - val_accuracy: 0.9804\n",
      "Epoch 750/1000\n",
      "202/202 [==============================] - 0s 93us/step - loss: 2.1583e-04 - accuracy: 1.0000 - val_loss: 0.2460 - val_accuracy: 0.9804\n",
      "Epoch 751/1000\n",
      "202/202 [==============================] - 0s 99us/step - loss: 2.1587e-04 - accuracy: 1.0000 - val_loss: 0.2495 - val_accuracy: 0.9804\n",
      "Epoch 752/1000\n",
      "202/202 [==============================] - 0s 95us/step - loss: 2.2335e-04 - accuracy: 1.0000 - val_loss: 0.2595 - val_accuracy: 0.9804\n",
      "Epoch 753/1000\n",
      "202/202 [==============================] - 0s 93us/step - loss: 2.1586e-04 - accuracy: 1.0000 - val_loss: 0.2536 - val_accuracy: 0.9804\n",
      "Epoch 754/1000\n",
      "202/202 [==============================] - 0s 95us/step - loss: 2.1028e-04 - accuracy: 1.0000 - val_loss: 0.2537 - val_accuracy: 0.9804\n",
      "Epoch 755/1000\n",
      "202/202 [==============================] - 0s 84us/step - loss: 2.0658e-04 - accuracy: 1.0000 - val_loss: 0.2493 - val_accuracy: 0.9804\n",
      "Epoch 756/1000\n",
      "202/202 [==============================] - 0s 81us/step - loss: 2.2352e-04 - accuracy: 1.0000 - val_loss: 0.2448 - val_accuracy: 0.9804\n",
      "Epoch 757/1000\n",
      "202/202 [==============================] - 0s 98us/step - loss: 2.0745e-04 - accuracy: 1.0000 - val_loss: 0.2563 - val_accuracy: 0.9804\n",
      "Epoch 758/1000\n",
      "202/202 [==============================] - 0s 98us/step - loss: 2.0781e-04 - accuracy: 1.0000 - val_loss: 0.2602 - val_accuracy: 0.9804\n",
      "Epoch 759/1000\n",
      "202/202 [==============================] - 0s 97us/step - loss: 2.2248e-04 - accuracy: 1.0000 - val_loss: 0.2592 - val_accuracy: 0.9804\n",
      "Epoch 760/1000\n",
      "202/202 [==============================] - 0s 104us/step - loss: 2.1314e-04 - accuracy: 1.0000 - val_loss: 0.2491 - val_accuracy: 0.9804\n",
      "Epoch 761/1000\n",
      "202/202 [==============================] - 0s 85us/step - loss: 1.9920e-04 - accuracy: 1.0000 - val_loss: 0.2546 - val_accuracy: 0.9804\n",
      "Epoch 762/1000\n",
      "202/202 [==============================] - 0s 76us/step - loss: 1.9834e-04 - accuracy: 1.0000 - val_loss: 0.2606 - val_accuracy: 0.9804\n",
      "Epoch 763/1000\n",
      "202/202 [==============================] - 0s 83us/step - loss: 2.1931e-04 - accuracy: 1.0000 - val_loss: 0.2587 - val_accuracy: 0.9804\n",
      "Epoch 764/1000\n",
      "202/202 [==============================] - 0s 86us/step - loss: 2.0501e-04 - accuracy: 1.0000 - val_loss: 0.2545 - val_accuracy: 0.9804\n",
      "Epoch 765/1000\n",
      "202/202 [==============================] - 0s 120us/step - loss: 2.0882e-04 - accuracy: 1.0000 - val_loss: 0.2496 - val_accuracy: 0.9804\n",
      "Epoch 766/1000\n",
      "202/202 [==============================] - 0s 103us/step - loss: 2.0943e-04 - accuracy: 1.0000 - val_loss: 0.2555 - val_accuracy: 0.9804\n",
      "Epoch 767/1000\n",
      "202/202 [==============================] - 0s 106us/step - loss: 1.9951e-04 - accuracy: 1.0000 - val_loss: 0.2545 - val_accuracy: 0.9804\n",
      "Epoch 768/1000\n",
      "202/202 [==============================] - 0s 108us/step - loss: 1.9711e-04 - accuracy: 1.0000 - val_loss: 0.2543 - val_accuracy: 0.9804\n",
      "Epoch 769/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202/202 [==============================] - 0s 90us/step - loss: 2.0044e-04 - accuracy: 1.0000 - val_loss: 0.2568 - val_accuracy: 0.9804\n",
      "Epoch 770/1000\n",
      "202/202 [==============================] - 0s 96us/step - loss: 1.9415e-04 - accuracy: 1.0000 - val_loss: 0.2489 - val_accuracy: 0.9804\n",
      "Epoch 771/1000\n",
      "202/202 [==============================] - 0s 85us/step - loss: 2.0175e-04 - accuracy: 1.0000 - val_loss: 0.2512 - val_accuracy: 0.9804\n",
      "Epoch 772/1000\n",
      "202/202 [==============================] - 0s 99us/step - loss: 1.9770e-04 - accuracy: 1.0000 - val_loss: 0.2524 - val_accuracy: 0.9804\n",
      "Epoch 773/1000\n",
      "202/202 [==============================] - 0s 74us/step - loss: 2.1037e-04 - accuracy: 1.0000 - val_loss: 0.2631 - val_accuracy: 0.9804\n",
      "Epoch 774/1000\n",
      "202/202 [==============================] - 0s 85us/step - loss: 2.0444e-04 - accuracy: 1.0000 - val_loss: 0.2559 - val_accuracy: 0.9804\n",
      "Epoch 775/1000\n",
      "202/202 [==============================] - 0s 96us/step - loss: 1.8966e-04 - accuracy: 1.0000 - val_loss: 0.2564 - val_accuracy: 0.9804\n",
      "Epoch 776/1000\n",
      "202/202 [==============================] - 0s 87us/step - loss: 1.9516e-04 - accuracy: 1.0000 - val_loss: 0.2588 - val_accuracy: 0.9804\n",
      "Epoch 777/1000\n",
      "202/202 [==============================] - 0s 84us/step - loss: 1.9109e-04 - accuracy: 1.0000 - val_loss: 0.2534 - val_accuracy: 0.9804\n",
      "Epoch 778/1000\n",
      "202/202 [==============================] - 0s 91us/step - loss: 1.9630e-04 - accuracy: 1.0000 - val_loss: 0.2535 - val_accuracy: 0.9804\n",
      "Epoch 779/1000\n",
      "202/202 [==============================] - 0s 95us/step - loss: 1.9569e-04 - accuracy: 1.0000 - val_loss: 0.2583 - val_accuracy: 0.9804\n",
      "Epoch 780/1000\n",
      "202/202 [==============================] - 0s 87us/step - loss: 1.9204e-04 - accuracy: 1.0000 - val_loss: 0.2570 - val_accuracy: 0.9804\n",
      "Epoch 781/1000\n",
      "202/202 [==============================] - 0s 98us/step - loss: 1.8304e-04 - accuracy: 1.0000 - val_loss: 0.2627 - val_accuracy: 0.9804\n",
      "Epoch 782/1000\n",
      "202/202 [==============================] - 0s 96us/step - loss: 1.9177e-04 - accuracy: 1.0000 - val_loss: 0.2639 - val_accuracy: 0.9804\n",
      "Epoch 783/1000\n",
      "202/202 [==============================] - 0s 114us/step - loss: 1.8388e-04 - accuracy: 1.0000 - val_loss: 0.2573 - val_accuracy: 0.9804\n",
      "Epoch 784/1000\n",
      "202/202 [==============================] - 0s 75us/step - loss: 1.8762e-04 - accuracy: 1.0000 - val_loss: 0.2578 - val_accuracy: 0.9804\n",
      "Epoch 785/1000\n",
      "202/202 [==============================] - 0s 82us/step - loss: 1.8293e-04 - accuracy: 1.0000 - val_loss: 0.2626 - val_accuracy: 0.9804\n",
      "Epoch 786/1000\n",
      "202/202 [==============================] - 0s 85us/step - loss: 1.9191e-04 - accuracy: 1.0000 - val_loss: 0.2676 - val_accuracy: 0.9804\n",
      "Epoch 787/1000\n",
      "202/202 [==============================] - 0s 83us/step - loss: 1.9160e-04 - accuracy: 1.0000 - val_loss: 0.2541 - val_accuracy: 0.9804\n",
      "Epoch 788/1000\n",
      "202/202 [==============================] - 0s 81us/step - loss: 1.8972e-04 - accuracy: 1.0000 - val_loss: 0.2531 - val_accuracy: 0.9804\n",
      "Epoch 789/1000\n",
      "202/202 [==============================] - 0s 98us/step - loss: 1.7612e-04 - accuracy: 1.0000 - val_loss: 0.2617 - val_accuracy: 0.9804\n",
      "Epoch 790/1000\n",
      "202/202 [==============================] - 0s 89us/step - loss: 1.8443e-04 - accuracy: 1.0000 - val_loss: 0.2635 - val_accuracy: 0.9804\n",
      "Epoch 791/1000\n",
      "202/202 [==============================] - 0s 87us/step - loss: 1.8299e-04 - accuracy: 1.0000 - val_loss: 0.2581 - val_accuracy: 0.9804\n",
      "Epoch 792/1000\n",
      "202/202 [==============================] - 0s 94us/step - loss: 1.7605e-04 - accuracy: 1.0000 - val_loss: 0.2565 - val_accuracy: 0.9804\n",
      "Epoch 793/1000\n",
      "202/202 [==============================] - 0s 101us/step - loss: 1.7200e-04 - accuracy: 1.0000 - val_loss: 0.2634 - val_accuracy: 0.9804\n",
      "Epoch 794/1000\n",
      "202/202 [==============================] - 0s 72us/step - loss: 1.7432e-04 - accuracy: 1.0000 - val_loss: 0.2643 - val_accuracy: 0.9804\n",
      "Epoch 795/1000\n",
      "202/202 [==============================] - 0s 93us/step - loss: 1.7708e-04 - accuracy: 1.0000 - val_loss: 0.2633 - val_accuracy: 0.9804\n",
      "Epoch 796/1000\n",
      "202/202 [==============================] - 0s 83us/step - loss: 1.8415e-04 - accuracy: 1.0000 - val_loss: 0.2509 - val_accuracy: 0.9804\n",
      "Epoch 797/1000\n",
      "202/202 [==============================] - 0s 85us/step - loss: 1.9028e-04 - accuracy: 1.0000 - val_loss: 0.2544 - val_accuracy: 0.9804\n",
      "Epoch 798/1000\n",
      "202/202 [==============================] - 0s 77us/step - loss: 1.7850e-04 - accuracy: 1.0000 - val_loss: 0.2666 - val_accuracy: 0.9804\n",
      "Epoch 799/1000\n",
      "202/202 [==============================] - 0s 96us/step - loss: 1.9680e-04 - accuracy: 1.0000 - val_loss: 0.2695 - val_accuracy: 0.9804\n",
      "Epoch 800/1000\n",
      "202/202 [==============================] - 0s 97us/step - loss: 1.7116e-04 - accuracy: 1.0000 - val_loss: 0.2563 - val_accuracy: 0.9804\n",
      "Epoch 801/1000\n",
      "202/202 [==============================] - 0s 98us/step - loss: 1.7114e-04 - accuracy: 1.0000 - val_loss: 0.2571 - val_accuracy: 0.9804\n",
      "Epoch 802/1000\n",
      "202/202 [==============================] - 0s 103us/step - loss: 1.7037e-04 - accuracy: 1.0000 - val_loss: 0.2604 - val_accuracy: 0.9804\n",
      "Epoch 803/1000\n",
      "202/202 [==============================] - 0s 91us/step - loss: 1.6714e-04 - accuracy: 1.0000 - val_loss: 0.2651 - val_accuracy: 0.9804\n",
      "Epoch 804/1000\n",
      "202/202 [==============================] - 0s 100us/step - loss: 1.7325e-04 - accuracy: 1.0000 - val_loss: 0.2619 - val_accuracy: 0.9804\n",
      "Epoch 805/1000\n",
      "202/202 [==============================] - 0s 96us/step - loss: 1.6498e-04 - accuracy: 1.0000 - val_loss: 0.2650 - val_accuracy: 0.9804\n",
      "Epoch 806/1000\n",
      "202/202 [==============================] - 0s 79us/step - loss: 1.6470e-04 - accuracy: 1.0000 - val_loss: 0.2664 - val_accuracy: 0.9804\n",
      "Epoch 807/1000\n",
      "202/202 [==============================] - 0s 79us/step - loss: 1.6778e-04 - accuracy: 1.0000 - val_loss: 0.2680 - val_accuracy: 0.9804\n",
      "Epoch 808/1000\n",
      "202/202 [==============================] - 0s 90us/step - loss: 1.6390e-04 - accuracy: 1.0000 - val_loss: 0.2633 - val_accuracy: 0.9804\n",
      "Epoch 809/1000\n",
      "202/202 [==============================] - 0s 86us/step - loss: 1.7175e-04 - accuracy: 1.0000 - val_loss: 0.2593 - val_accuracy: 0.9804\n",
      "Epoch 810/1000\n",
      "202/202 [==============================] - 0s 109us/step - loss: 1.7268e-04 - accuracy: 1.0000 - val_loss: 0.2669 - val_accuracy: 0.9804\n",
      "Epoch 811/1000\n",
      "202/202 [==============================] - 0s 85us/step - loss: 1.6233e-04 - accuracy: 1.0000 - val_loss: 0.2648 - val_accuracy: 0.9804\n",
      "Epoch 812/1000\n",
      "202/202 [==============================] - 0s 89us/step - loss: 1.6263e-04 - accuracy: 1.0000 - val_loss: 0.2598 - val_accuracy: 0.9804\n",
      "Epoch 813/1000\n",
      "202/202 [==============================] - 0s 82us/step - loss: 1.5975e-04 - accuracy: 1.0000 - val_loss: 0.2596 - val_accuracy: 0.9804\n",
      "Epoch 814/1000\n",
      "202/202 [==============================] - 0s 92us/step - loss: 1.6453e-04 - accuracy: 1.0000 - val_loss: 0.2637 - val_accuracy: 0.9804\n",
      "Epoch 815/1000\n",
      "202/202 [==============================] - 0s 110us/step - loss: 1.7235e-04 - accuracy: 1.0000 - val_loss: 0.2681 - val_accuracy: 0.9804\n",
      "Epoch 816/1000\n",
      "202/202 [==============================] - 0s 94us/step - loss: 1.5266e-04 - accuracy: 1.0000 - val_loss: 0.2581 - val_accuracy: 0.9804\n",
      "Epoch 817/1000\n",
      "202/202 [==============================] - 0s 124us/step - loss: 1.6788e-04 - accuracy: 1.0000 - val_loss: 0.2581 - val_accuracy: 0.9804\n",
      "Epoch 818/1000\n",
      "202/202 [==============================] - 0s 99us/step - loss: 1.6039e-04 - accuracy: 1.0000 - val_loss: 0.2656 - val_accuracy: 0.9804\n",
      "Epoch 819/1000\n",
      "202/202 [==============================] - 0s 95us/step - loss: 1.6400e-04 - accuracy: 1.0000 - val_loss: 0.2680 - val_accuracy: 0.9804\n",
      "Epoch 820/1000\n",
      "202/202 [==============================] - 0s 96us/step - loss: 1.5851e-04 - accuracy: 1.0000 - val_loss: 0.2654 - val_accuracy: 0.9804\n",
      "Epoch 821/1000\n",
      "202/202 [==============================] - 0s 89us/step - loss: 1.5457e-04 - accuracy: 1.0000 - val_loss: 0.2651 - val_accuracy: 0.9804\n",
      "Epoch 822/1000\n",
      "202/202 [==============================] - 0s 113us/step - loss: 1.5478e-04 - accuracy: 1.0000 - val_loss: 0.2648 - val_accuracy: 0.9804\n",
      "Epoch 823/1000\n",
      "202/202 [==============================] - 0s 89us/step - loss: 1.5607e-04 - accuracy: 1.0000 - val_loss: 0.2649 - val_accuracy: 0.9804\n",
      "Epoch 824/1000\n",
      "202/202 [==============================] - 0s 98us/step - loss: 1.5466e-04 - accuracy: 1.0000 - val_loss: 0.2657 - val_accuracy: 0.9804\n",
      "Epoch 825/1000\n",
      "202/202 [==============================] - 0s 110us/step - loss: 1.5093e-04 - accuracy: 1.0000 - val_loss: 0.2672 - val_accuracy: 0.9804\n",
      "Epoch 826/1000\n",
      "202/202 [==============================] - 0s 85us/step - loss: 1.5124e-04 - accuracy: 1.0000 - val_loss: 0.2683 - val_accuracy: 0.9804\n",
      "Epoch 827/1000\n",
      "202/202 [==============================] - 0s 87us/step - loss: 1.5897e-04 - accuracy: 1.0000 - val_loss: 0.2649 - val_accuracy: 0.9804\n",
      "Epoch 828/1000\n",
      "202/202 [==============================] - 0s 84us/step - loss: 1.5113e-04 - accuracy: 1.0000 - val_loss: 0.2667 - val_accuracy: 0.9804\n",
      "Epoch 829/1000\n",
      "202/202 [==============================] - 0s 79us/step - loss: 1.4711e-04 - accuracy: 1.0000 - val_loss: 0.2613 - val_accuracy: 0.9804\n",
      "Epoch 830/1000\n",
      "202/202 [==============================] - 0s 103us/step - loss: 1.5140e-04 - accuracy: 1.0000 - val_loss: 0.2635 - val_accuracy: 0.9804\n",
      "Epoch 831/1000\n",
      "202/202 [==============================] - 0s 87us/step - loss: 1.4894e-04 - accuracy: 1.0000 - val_loss: 0.2671 - val_accuracy: 0.9804\n",
      "Epoch 832/1000\n",
      "202/202 [==============================] - 0s 88us/step - loss: 1.4758e-04 - accuracy: 1.0000 - val_loss: 0.2679 - val_accuracy: 0.9804\n",
      "Epoch 833/1000\n",
      "202/202 [==============================] - 0s 91us/step - loss: 1.4705e-04 - accuracy: 1.0000 - val_loss: 0.2682 - val_accuracy: 0.9804\n",
      "Epoch 834/1000\n",
      "202/202 [==============================] - 0s 87us/step - loss: 1.4823e-04 - accuracy: 1.0000 - val_loss: 0.2669 - val_accuracy: 0.9804\n",
      "Epoch 835/1000\n",
      "202/202 [==============================] - 0s 110us/step - loss: 1.5163e-04 - accuracy: 1.0000 - val_loss: 0.2718 - val_accuracy: 0.9804\n",
      "Epoch 836/1000\n",
      "202/202 [==============================] - 0s 98us/step - loss: 1.4735e-04 - accuracy: 1.0000 - val_loss: 0.2689 - val_accuracy: 0.9804\n",
      "Epoch 837/1000\n",
      "202/202 [==============================] - 0s 89us/step - loss: 1.4523e-04 - accuracy: 1.0000 - val_loss: 0.2684 - val_accuracy: 0.9804\n",
      "Epoch 838/1000\n",
      "202/202 [==============================] - 0s 86us/step - loss: 1.5277e-04 - accuracy: 1.0000 - val_loss: 0.2677 - val_accuracy: 0.9804\n",
      "Epoch 839/1000\n",
      "202/202 [==============================] - 0s 92us/step - loss: 1.4550e-04 - accuracy: 1.0000 - val_loss: 0.2653 - val_accuracy: 0.9804\n",
      "Epoch 840/1000\n",
      "202/202 [==============================] - 0s 87us/step - loss: 1.4217e-04 - accuracy: 1.0000 - val_loss: 0.2683 - val_accuracy: 0.9804\n",
      "Epoch 841/1000\n",
      "202/202 [==============================] - 0s 86us/step - loss: 1.4688e-04 - accuracy: 1.0000 - val_loss: 0.2701 - val_accuracy: 0.9804\n",
      "Epoch 842/1000\n",
      "202/202 [==============================] - 0s 87us/step - loss: 1.4113e-04 - accuracy: 1.0000 - val_loss: 0.2674 - val_accuracy: 0.9804\n",
      "Epoch 843/1000\n",
      "202/202 [==============================] - 0s 80us/step - loss: 1.4067e-04 - accuracy: 1.0000 - val_loss: 0.2680 - val_accuracy: 0.9804\n",
      "Epoch 844/1000\n",
      "202/202 [==============================] - 0s 93us/step - loss: 1.4153e-04 - accuracy: 1.0000 - val_loss: 0.2678 - val_accuracy: 0.9804\n",
      "Epoch 845/1000\n",
      "202/202 [==============================] - 0s 95us/step - loss: 1.4162e-04 - accuracy: 1.0000 - val_loss: 0.2682 - val_accuracy: 0.9804\n",
      "Epoch 846/1000\n",
      "202/202 [==============================] - 0s 97us/step - loss: 1.4657e-04 - accuracy: 1.0000 - val_loss: 0.2720 - val_accuracy: 0.9804\n",
      "Epoch 847/1000\n",
      "202/202 [==============================] - 0s 82us/step - loss: 1.3426e-04 - accuracy: 1.0000 - val_loss: 0.2607 - val_accuracy: 0.9804\n",
      "Epoch 848/1000\n",
      "202/202 [==============================] - 0s 86us/step - loss: 1.4935e-04 - accuracy: 1.0000 - val_loss: 0.2639 - val_accuracy: 0.9804\n",
      "Epoch 849/1000\n",
      "202/202 [==============================] - 0s 89us/step - loss: 1.5862e-04 - accuracy: 1.0000 - val_loss: 0.2778 - val_accuracy: 0.9804\n",
      "Epoch 850/1000\n",
      "202/202 [==============================] - 0s 106us/step - loss: 1.6592e-04 - accuracy: 1.0000 - val_loss: 0.2628 - val_accuracy: 0.9804\n",
      "Epoch 851/1000\n",
      "202/202 [==============================] - 0s 97us/step - loss: 1.3942e-04 - accuracy: 1.0000 - val_loss: 0.2684 - val_accuracy: 0.9804\n",
      "Epoch 852/1000\n",
      "202/202 [==============================] - 0s 85us/step - loss: 1.3318e-04 - accuracy: 1.0000 - val_loss: 0.2795 - val_accuracy: 0.9804\n",
      "Epoch 853/1000\n",
      "202/202 [==============================] - 0s 98us/step - loss: 1.4880e-04 - accuracy: 1.0000 - val_loss: 0.2789 - val_accuracy: 0.9804\n",
      "Epoch 854/1000\n",
      "202/202 [==============================] - 0s 84us/step - loss: 1.3315e-04 - accuracy: 1.0000 - val_loss: 0.2687 - val_accuracy: 0.9804\n",
      "Epoch 855/1000\n",
      "202/202 [==============================] - 0s 106us/step - loss: 1.4427e-04 - accuracy: 1.0000 - val_loss: 0.2567 - val_accuracy: 0.9804\n",
      "Epoch 856/1000\n",
      "202/202 [==============================] - 0s 81us/step - loss: 1.5473e-04 - accuracy: 1.0000 - val_loss: 0.2667 - val_accuracy: 0.9804\n",
      "Epoch 857/1000\n",
      "202/202 [==============================] - 0s 97us/step - loss: 1.3443e-04 - accuracy: 1.0000 - val_loss: 0.2793 - val_accuracy: 0.9804\n",
      "Epoch 858/1000\n",
      "202/202 [==============================] - 0s 95us/step - loss: 1.4203e-04 - accuracy: 1.0000 - val_loss: 0.2812 - val_accuracy: 0.9804\n",
      "Epoch 859/1000\n",
      "202/202 [==============================] - 0s 96us/step - loss: 1.4330e-04 - accuracy: 1.0000 - val_loss: 0.2695 - val_accuracy: 0.9804\n",
      "Epoch 860/1000\n",
      "202/202 [==============================] - 0s 78us/step - loss: 1.3475e-04 - accuracy: 1.0000 - val_loss: 0.2668 - val_accuracy: 0.9804\n",
      "Epoch 861/1000\n",
      "202/202 [==============================] - 0s 93us/step - loss: 1.3212e-04 - accuracy: 1.0000 - val_loss: 0.2739 - val_accuracy: 0.9804\n",
      "Epoch 862/1000\n",
      "202/202 [==============================] - 0s 90us/step - loss: 1.3780e-04 - accuracy: 1.0000 - val_loss: 0.2784 - val_accuracy: 0.9804\n",
      "Epoch 863/1000\n",
      "202/202 [==============================] - 0s 100us/step - loss: 1.3087e-04 - accuracy: 1.0000 - val_loss: 0.2738 - val_accuracy: 0.9804\n",
      "Epoch 864/1000\n",
      "202/202 [==============================] - 0s 96us/step - loss: 1.2987e-04 - accuracy: 1.0000 - val_loss: 0.2689 - val_accuracy: 0.9804\n",
      "Epoch 865/1000\n",
      "202/202 [==============================] - 0s 86us/step - loss: 1.3539e-04 - accuracy: 1.0000 - val_loss: 0.2730 - val_accuracy: 0.9804\n",
      "Epoch 866/1000\n",
      "202/202 [==============================] - 0s 83us/step - loss: 1.2428e-04 - accuracy: 1.0000 - val_loss: 0.2764 - val_accuracy: 0.9804\n",
      "Epoch 867/1000\n",
      "202/202 [==============================] - 0s 91us/step - loss: 1.3737e-04 - accuracy: 1.0000 - val_loss: 0.2748 - val_accuracy: 0.9804\n",
      "Epoch 868/1000\n",
      "202/202 [==============================] - 0s 107us/step - loss: 1.2296e-04 - accuracy: 1.0000 - val_loss: 0.2724 - val_accuracy: 0.9804\n",
      "Epoch 869/1000\n",
      "202/202 [==============================] - 0s 106us/step - loss: 1.3128e-04 - accuracy: 1.0000 - val_loss: 0.2702 - val_accuracy: 0.9804\n",
      "Epoch 870/1000\n",
      "202/202 [==============================] - 0s 90us/step - loss: 1.3125e-04 - accuracy: 1.0000 - val_loss: 0.2756 - val_accuracy: 0.9804\n",
      "Epoch 871/1000\n",
      "202/202 [==============================] - 0s 95us/step - loss: 1.2536e-04 - accuracy: 1.0000 - val_loss: 0.2738 - val_accuracy: 0.9804\n",
      "Epoch 872/1000\n",
      "202/202 [==============================] - 0s 100us/step - loss: 1.2484e-04 - accuracy: 1.0000 - val_loss: 0.2741 - val_accuracy: 0.9804\n",
      "Epoch 873/1000\n",
      "202/202 [==============================] - 0s 100us/step - loss: 1.2564e-04 - accuracy: 1.0000 - val_loss: 0.2741 - val_accuracy: 0.9804\n",
      "Epoch 874/1000\n",
      "202/202 [==============================] - 0s 100us/step - loss: 1.2202e-04 - accuracy: 1.0000 - val_loss: 0.2779 - val_accuracy: 0.9804\n",
      "Epoch 875/1000\n",
      "202/202 [==============================] - 0s 106us/step - loss: 1.2743e-04 - accuracy: 1.0000 - val_loss: 0.2800 - val_accuracy: 0.9804\n",
      "Epoch 876/1000\n",
      "202/202 [==============================] - 0s 102us/step - loss: 1.1990e-04 - accuracy: 1.0000 - val_loss: 0.2704 - val_accuracy: 0.9804\n",
      "Epoch 877/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202/202 [==============================] - 0s 100us/step - loss: 1.2373e-04 - accuracy: 1.0000 - val_loss: 0.2705 - val_accuracy: 0.9804\n",
      "Epoch 878/1000\n",
      "202/202 [==============================] - 0s 89us/step - loss: 1.2165e-04 - accuracy: 1.0000 - val_loss: 0.2733 - val_accuracy: 0.9804\n",
      "Epoch 879/1000\n",
      "202/202 [==============================] - 0s 90us/step - loss: 1.2107e-04 - accuracy: 1.0000 - val_loss: 0.2753 - val_accuracy: 0.9804\n",
      "Epoch 880/1000\n",
      "202/202 [==============================] - 0s 82us/step - loss: 1.1922e-04 - accuracy: 1.0000 - val_loss: 0.2770 - val_accuracy: 0.9804\n",
      "Epoch 881/1000\n",
      "202/202 [==============================] - 0s 83us/step - loss: 1.2096e-04 - accuracy: 1.0000 - val_loss: 0.2761 - val_accuracy: 0.9804\n",
      "Epoch 882/1000\n",
      "202/202 [==============================] - 0s 88us/step - loss: 1.2619e-04 - accuracy: 1.0000 - val_loss: 0.2792 - val_accuracy: 0.9804\n",
      "Epoch 883/1000\n",
      "202/202 [==============================] - 0s 80us/step - loss: 1.2031e-04 - accuracy: 1.0000 - val_loss: 0.2720 - val_accuracy: 0.9804\n",
      "Epoch 884/1000\n",
      "202/202 [==============================] - 0s 82us/step - loss: 1.2089e-04 - accuracy: 1.0000 - val_loss: 0.2673 - val_accuracy: 0.9804\n",
      "Epoch 885/1000\n",
      "202/202 [==============================] - 0s 102us/step - loss: 1.2889e-04 - accuracy: 1.0000 - val_loss: 0.2722 - val_accuracy: 0.9804\n",
      "Epoch 886/1000\n",
      "202/202 [==============================] - 0s 89us/step - loss: 1.1543e-04 - accuracy: 1.0000 - val_loss: 0.2794 - val_accuracy: 0.9804\n",
      "Epoch 887/1000\n",
      "202/202 [==============================] - 0s 79us/step - loss: 1.2207e-04 - accuracy: 1.0000 - val_loss: 0.2803 - val_accuracy: 0.9804\n",
      "Epoch 888/1000\n",
      "202/202 [==============================] - 0s 87us/step - loss: 1.2369e-04 - accuracy: 1.0000 - val_loss: 0.2816 - val_accuracy: 0.9804\n",
      "Epoch 889/1000\n",
      "202/202 [==============================] - 0s 86us/step - loss: 1.1737e-04 - accuracy: 1.0000 - val_loss: 0.2737 - val_accuracy: 0.9804\n",
      "Epoch 890/1000\n",
      "202/202 [==============================] - 0s 102us/step - loss: 1.1662e-04 - accuracy: 1.0000 - val_loss: 0.2736 - val_accuracy: 0.9804\n",
      "Epoch 891/1000\n",
      "202/202 [==============================] - 0s 92us/step - loss: 1.1444e-04 - accuracy: 1.0000 - val_loss: 0.2770 - val_accuracy: 0.9804\n",
      "Epoch 892/1000\n",
      "202/202 [==============================] - 0s 84us/step - loss: 1.1404e-04 - accuracy: 1.0000 - val_loss: 0.2767 - val_accuracy: 0.9804\n",
      "Epoch 893/1000\n",
      "202/202 [==============================] - 0s 83us/step - loss: 1.1799e-04 - accuracy: 1.0000 - val_loss: 0.2751 - val_accuracy: 0.9804\n",
      "Epoch 894/1000\n",
      "202/202 [==============================] - 0s 90us/step - loss: 1.1511e-04 - accuracy: 1.0000 - val_loss: 0.2714 - val_accuracy: 0.9804\n",
      "Epoch 895/1000\n",
      "202/202 [==============================] - 0s 86us/step - loss: 1.1687e-04 - accuracy: 1.0000 - val_loss: 0.2764 - val_accuracy: 0.9804\n",
      "Epoch 896/1000\n",
      "202/202 [==============================] - 0s 107us/step - loss: 1.1380e-04 - accuracy: 1.0000 - val_loss: 0.2832 - val_accuracy: 0.9804\n",
      "Epoch 897/1000\n",
      "202/202 [==============================] - 0s 88us/step - loss: 1.2404e-04 - accuracy: 1.0000 - val_loss: 0.2821 - val_accuracy: 0.9804\n",
      "Epoch 898/1000\n",
      "202/202 [==============================] - 0s 98us/step - loss: 1.0336e-04 - accuracy: 1.0000 - val_loss: 0.2646 - val_accuracy: 0.9804\n",
      "Epoch 899/1000\n",
      "202/202 [==============================] - 0s 89us/step - loss: 1.2945e-04 - accuracy: 1.0000 - val_loss: 0.2707 - val_accuracy: 0.9804\n",
      "Epoch 900/1000\n",
      "202/202 [==============================] - 0s 94us/step - loss: 1.1420e-04 - accuracy: 1.0000 - val_loss: 0.2797 - val_accuracy: 0.9804\n",
      "Epoch 901/1000\n",
      "202/202 [==============================] - 0s 105us/step - loss: 1.0838e-04 - accuracy: 1.0000 - val_loss: 0.2799 - val_accuracy: 0.9804\n",
      "Epoch 902/1000\n",
      "202/202 [==============================] - 0s 95us/step - loss: 1.1645e-04 - accuracy: 1.0000 - val_loss: 0.2790 - val_accuracy: 0.9804\n",
      "Epoch 903/1000\n",
      "202/202 [==============================] - 0s 86us/step - loss: 1.1541e-04 - accuracy: 1.0000 - val_loss: 0.2814 - val_accuracy: 0.9804\n",
      "Epoch 904/1000\n",
      "202/202 [==============================] - 0s 75us/step - loss: 1.1388e-04 - accuracy: 1.0000 - val_loss: 0.2837 - val_accuracy: 0.9804\n",
      "Epoch 905/1000\n",
      "202/202 [==============================] - 0s 101us/step - loss: 1.1122e-04 - accuracy: 1.0000 - val_loss: 0.2712 - val_accuracy: 0.9804\n",
      "Epoch 906/1000\n",
      "202/202 [==============================] - 0s 83us/step - loss: 1.1926e-04 - accuracy: 1.0000 - val_loss: 0.2717 - val_accuracy: 0.9804\n",
      "Epoch 907/1000\n",
      "202/202 [==============================] - 0s 95us/step - loss: 1.1252e-04 - accuracy: 1.0000 - val_loss: 0.2748 - val_accuracy: 0.9804\n",
      "Epoch 908/1000\n",
      "202/202 [==============================] - 0s 79us/step - loss: 1.1777e-04 - accuracy: 1.0000 - val_loss: 0.2833 - val_accuracy: 0.9804\n",
      "Epoch 909/1000\n",
      "202/202 [==============================] - 0s 88us/step - loss: 1.0848e-04 - accuracy: 1.0000 - val_loss: 0.2772 - val_accuracy: 0.9804\n",
      "Epoch 910/1000\n",
      "202/202 [==============================] - 0s 107us/step - loss: 1.1271e-04 - accuracy: 1.0000 - val_loss: 0.2753 - val_accuracy: 0.9804\n",
      "Epoch 911/1000\n",
      "202/202 [==============================] - 0s 89us/step - loss: 1.1284e-04 - accuracy: 1.0000 - val_loss: 0.2851 - val_accuracy: 0.9804\n",
      "Epoch 912/1000\n",
      "202/202 [==============================] - 0s 82us/step - loss: 1.1180e-04 - accuracy: 1.0000 - val_loss: 0.2822 - val_accuracy: 0.9804\n",
      "Epoch 913/1000\n",
      "202/202 [==============================] - 0s 91us/step - loss: 1.1227e-04 - accuracy: 1.0000 - val_loss: 0.2632 - val_accuracy: 0.9804\n",
      "Epoch 914/1000\n",
      "202/202 [==============================] - 0s 86us/step - loss: 1.2319e-04 - accuracy: 1.0000 - val_loss: 0.2764 - val_accuracy: 0.9804\n",
      "Epoch 915/1000\n",
      "202/202 [==============================] - 0s 96us/step - loss: 1.0378e-04 - accuracy: 1.0000 - val_loss: 0.2829 - val_accuracy: 0.9804\n",
      "Epoch 916/1000\n",
      "202/202 [==============================] - 0s 96us/step - loss: 1.0918e-04 - accuracy: 1.0000 - val_loss: 0.2838 - val_accuracy: 0.9804\n",
      "Epoch 917/1000\n",
      "202/202 [==============================] - 0s 81us/step - loss: 1.1002e-04 - accuracy: 1.0000 - val_loss: 0.2763 - val_accuracy: 0.9804\n",
      "Epoch 918/1000\n",
      "202/202 [==============================] - 0s 88us/step - loss: 1.0251e-04 - accuracy: 1.0000 - val_loss: 0.2797 - val_accuracy: 0.9804\n",
      "Epoch 919/1000\n",
      "202/202 [==============================] - 0s 92us/step - loss: 1.0083e-04 - accuracy: 1.0000 - val_loss: 0.2834 - val_accuracy: 0.9804\n",
      "Epoch 920/1000\n",
      "202/202 [==============================] - 0s 85us/step - loss: 1.0479e-04 - accuracy: 1.0000 - val_loss: 0.2853 - val_accuracy: 0.9804\n",
      "Epoch 921/1000\n",
      "202/202 [==============================] - 0s 116us/step - loss: 1.0603e-04 - accuracy: 1.0000 - val_loss: 0.2796 - val_accuracy: 0.9804\n",
      "Epoch 922/1000\n",
      "202/202 [==============================] - 0s 91us/step - loss: 1.0038e-04 - accuracy: 1.0000 - val_loss: 0.2798 - val_accuracy: 0.9804\n",
      "Epoch 923/1000\n",
      "202/202 [==============================] - 0s 100us/step - loss: 9.9574e-05 - accuracy: 1.0000 - val_loss: 0.2812 - val_accuracy: 0.9804\n",
      "Epoch 924/1000\n",
      "202/202 [==============================] - 0s 82us/step - loss: 1.0020e-04 - accuracy: 1.0000 - val_loss: 0.2817 - val_accuracy: 0.9804\n",
      "Epoch 925/1000\n",
      "202/202 [==============================] - 0s 79us/step - loss: 1.0076e-04 - accuracy: 1.0000 - val_loss: 0.2843 - val_accuracy: 0.9804\n",
      "Epoch 926/1000\n",
      "202/202 [==============================] - 0s 95us/step - loss: 9.8402e-05 - accuracy: 1.0000 - val_loss: 0.2847 - val_accuracy: 0.9804\n",
      "Epoch 927/1000\n",
      "202/202 [==============================] - 0s 88us/step - loss: 9.9911e-05 - accuracy: 1.0000 - val_loss: 0.2847 - val_accuracy: 0.9804\n",
      "Epoch 928/1000\n",
      "202/202 [==============================] - 0s 117us/step - loss: 9.8153e-05 - accuracy: 1.0000 - val_loss: 0.2821 - val_accuracy: 0.9804\n",
      "Epoch 929/1000\n",
      "202/202 [==============================] - 0s 85us/step - loss: 9.9067e-05 - accuracy: 1.0000 - val_loss: 0.2776 - val_accuracy: 0.9804\n",
      "Epoch 930/1000\n",
      "202/202 [==============================] - 0s 120us/step - loss: 9.9589e-05 - accuracy: 1.0000 - val_loss: 0.2807 - val_accuracy: 0.9804\n",
      "Epoch 931/1000\n",
      "202/202 [==============================] - 0s 82us/step - loss: 9.4479e-05 - accuracy: 1.0000 - val_loss: 0.2891 - val_accuracy: 0.9804\n",
      "Epoch 932/1000\n",
      "202/202 [==============================] - 0s 101us/step - loss: 1.0619e-04 - accuracy: 1.0000 - val_loss: 0.2880 - val_accuracy: 0.9804\n",
      "Epoch 933/1000\n",
      "202/202 [==============================] - 0s 96us/step - loss: 9.7382e-05 - accuracy: 1.0000 - val_loss: 0.2820 - val_accuracy: 0.9804\n",
      "Epoch 934/1000\n",
      "202/202 [==============================] - 0s 94us/step - loss: 9.9861e-05 - accuracy: 1.0000 - val_loss: 0.2792 - val_accuracy: 0.9804\n",
      "Epoch 935/1000\n",
      "202/202 [==============================] - 0s 101us/step - loss: 9.4784e-05 - accuracy: 1.0000 - val_loss: 0.2795 - val_accuracy: 0.9804\n",
      "Epoch 936/1000\n",
      "202/202 [==============================] - 0s 93us/step - loss: 9.8551e-05 - accuracy: 1.0000 - val_loss: 0.2831 - val_accuracy: 0.9804\n",
      "Epoch 937/1000\n",
      "202/202 [==============================] - 0s 82us/step - loss: 9.5522e-05 - accuracy: 1.0000 - val_loss: 0.2844 - val_accuracy: 0.9804\n",
      "Epoch 938/1000\n",
      "202/202 [==============================] - 0s 95us/step - loss: 9.2790e-05 - accuracy: 1.0000 - val_loss: 0.2846 - val_accuracy: 0.9804\n",
      "Epoch 939/1000\n",
      "202/202 [==============================] - 0s 79us/step - loss: 9.3712e-05 - accuracy: 1.0000 - val_loss: 0.2836 - val_accuracy: 0.9804\n",
      "Epoch 940/1000\n",
      "202/202 [==============================] - 0s 86us/step - loss: 9.3522e-05 - accuracy: 1.0000 - val_loss: 0.2884 - val_accuracy: 0.9804\n",
      "Epoch 941/1000\n",
      "202/202 [==============================] - 0s 96us/step - loss: 9.6766e-05 - accuracy: 1.0000 - val_loss: 0.2836 - val_accuracy: 0.9804\n",
      "Epoch 942/1000\n",
      "202/202 [==============================] - 0s 82us/step - loss: 9.5357e-05 - accuracy: 1.0000 - val_loss: 0.2831 - val_accuracy: 0.9804\n",
      "Epoch 943/1000\n",
      "202/202 [==============================] - 0s 92us/step - loss: 1.1489e-04 - accuracy: 1.0000 - val_loss: 0.2684 - val_accuracy: 0.9804\n",
      "Epoch 944/1000\n",
      "202/202 [==============================] - 0s 87us/step - loss: 1.0158e-04 - accuracy: 1.0000 - val_loss: 0.2845 - val_accuracy: 0.9804\n",
      "Epoch 945/1000\n",
      "202/202 [==============================] - 0s 96us/step - loss: 9.1650e-05 - accuracy: 1.0000 - val_loss: 0.2964 - val_accuracy: 0.9804\n",
      "Epoch 946/1000\n",
      "202/202 [==============================] - 0s 102us/step - loss: 1.0047e-04 - accuracy: 1.0000 - val_loss: 0.2917 - val_accuracy: 0.9804\n",
      "Epoch 947/1000\n",
      "202/202 [==============================] - 0s 88us/step - loss: 9.0831e-05 - accuracy: 1.0000 - val_loss: 0.2827 - val_accuracy: 0.9804\n",
      "Epoch 948/1000\n",
      "202/202 [==============================] - 0s 93us/step - loss: 9.0852e-05 - accuracy: 1.0000 - val_loss: 0.2811 - val_accuracy: 0.9804\n",
      "Epoch 949/1000\n",
      "202/202 [==============================] - 0s 101us/step - loss: 8.8824e-05 - accuracy: 1.0000 - val_loss: 0.2844 - val_accuracy: 0.9804\n",
      "Epoch 950/1000\n",
      "202/202 [==============================] - 0s 79us/step - loss: 8.8338e-05 - accuracy: 1.0000 - val_loss: 0.2868 - val_accuracy: 0.9804\n",
      "Epoch 951/1000\n",
      "202/202 [==============================] - 0s 92us/step - loss: 8.7431e-05 - accuracy: 1.0000 - val_loss: 0.2879 - val_accuracy: 0.9804\n",
      "Epoch 952/1000\n",
      "202/202 [==============================] - 0s 90us/step - loss: 8.8510e-05 - accuracy: 1.0000 - val_loss: 0.2897 - val_accuracy: 0.9804\n",
      "Epoch 953/1000\n",
      "202/202 [==============================] - 0s 88us/step - loss: 9.0366e-05 - accuracy: 1.0000 - val_loss: 0.2871 - val_accuracy: 0.9804\n",
      "Epoch 954/1000\n",
      "202/202 [==============================] - 0s 87us/step - loss: 1.0010e-04 - accuracy: 1.0000 - val_loss: 0.2770 - val_accuracy: 0.9804\n",
      "Epoch 955/1000\n",
      "202/202 [==============================] - 0s 80us/step - loss: 9.1745e-05 - accuracy: 1.0000 - val_loss: 0.2841 - val_accuracy: 0.9804\n",
      "Epoch 956/1000\n",
      "202/202 [==============================] - 0s 99us/step - loss: 9.1868e-05 - accuracy: 1.0000 - val_loss: 0.2920 - val_accuracy: 0.9804\n",
      "Epoch 957/1000\n",
      "202/202 [==============================] - 0s 86us/step - loss: 8.7233e-05 - accuracy: 1.0000 - val_loss: 0.2906 - val_accuracy: 0.9804\n",
      "Epoch 958/1000\n",
      "202/202 [==============================] - 0s 87us/step - loss: 8.9829e-05 - accuracy: 1.0000 - val_loss: 0.2839 - val_accuracy: 0.9804\n",
      "Epoch 959/1000\n",
      "202/202 [==============================] - 0s 83us/step - loss: 9.4101e-05 - accuracy: 1.0000 - val_loss: 0.2887 - val_accuracy: 0.9804\n",
      "Epoch 960/1000\n",
      "202/202 [==============================] - 0s 108us/step - loss: 1.1183e-04 - accuracy: 1.0000 - val_loss: 0.2890 - val_accuracy: 0.9804\n",
      "Epoch 961/1000\n",
      "202/202 [==============================] - 0s 98us/step - loss: 8.8201e-05 - accuracy: 1.0000 - val_loss: 0.2851 - val_accuracy: 0.9804\n",
      "Epoch 962/1000\n",
      "202/202 [==============================] - 0s 88us/step - loss: 8.8844e-05 - accuracy: 1.0000 - val_loss: 0.2890 - val_accuracy: 0.9804\n",
      "Epoch 963/1000\n",
      "202/202 [==============================] - 0s 87us/step - loss: 8.3603e-05 - accuracy: 1.0000 - val_loss: 0.2935 - val_accuracy: 0.9804\n",
      "Epoch 964/1000\n",
      "202/202 [==============================] - 0s 88us/step - loss: 9.3377e-05 - accuracy: 1.0000 - val_loss: 0.2920 - val_accuracy: 0.9804\n",
      "Epoch 965/1000\n",
      "202/202 [==============================] - 0s 68us/step - loss: 8.9564e-05 - accuracy: 1.0000 - val_loss: 0.2867 - val_accuracy: 0.9804\n",
      "Epoch 966/1000\n",
      "202/202 [==============================] - 0s 101us/step - loss: 8.3085e-05 - accuracy: 1.0000 - val_loss: 0.2895 - val_accuracy: 0.9804\n",
      "Epoch 967/1000\n",
      "202/202 [==============================] - 0s 100us/step - loss: 8.4290e-05 - accuracy: 1.0000 - val_loss: 0.2921 - val_accuracy: 0.9804\n",
      "Epoch 968/1000\n",
      "202/202 [==============================] - 0s 93us/step - loss: 8.2379e-05 - accuracy: 1.0000 - val_loss: 0.2901 - val_accuracy: 0.9804\n",
      "Epoch 969/1000\n",
      "202/202 [==============================] - 0s 204us/step - loss: 8.7611e-05 - accuracy: 1.0000 - val_loss: 0.2799 - val_accuracy: 0.9804\n",
      "Epoch 970/1000\n",
      "202/202 [==============================] - 0s 93us/step - loss: 8.7971e-05 - accuracy: 1.0000 - val_loss: 0.2848 - val_accuracy: 0.9804\n",
      "Epoch 971/1000\n",
      "202/202 [==============================] - 0s 130us/step - loss: 8.3429e-05 - accuracy: 1.0000 - val_loss: 0.2931 - val_accuracy: 0.9804\n",
      "Epoch 972/1000\n",
      "202/202 [==============================] - 0s 92us/step - loss: 8.1893e-05 - accuracy: 1.0000 - val_loss: 0.2933 - val_accuracy: 0.9804\n",
      "Epoch 973/1000\n",
      "202/202 [==============================] - 0s 91us/step - loss: 8.1854e-05 - accuracy: 1.0000 - val_loss: 0.2885 - val_accuracy: 0.9804\n",
      "Epoch 974/1000\n",
      "202/202 [==============================] - 0s 108us/step - loss: 8.3699e-05 - accuracy: 1.0000 - val_loss: 0.2880 - val_accuracy: 0.9804\n",
      "Epoch 975/1000\n",
      "202/202 [==============================] - 0s 89us/step - loss: 8.1598e-05 - accuracy: 1.0000 - val_loss: 0.2939 - val_accuracy: 0.9804\n",
      "Epoch 976/1000\n",
      "202/202 [==============================] - 0s 75us/step - loss: 7.9369e-05 - accuracy: 1.0000 - val_loss: 0.2906 - val_accuracy: 0.9804\n",
      "Epoch 977/1000\n",
      "202/202 [==============================] - 0s 105us/step - loss: 7.8027e-05 - accuracy: 1.0000 - val_loss: 0.2892 - val_accuracy: 0.9804\n",
      "Epoch 978/1000\n",
      "202/202 [==============================] - 0s 98us/step - loss: 8.0391e-05 - accuracy: 1.0000 - val_loss: 0.2885 - val_accuracy: 0.9804\n",
      "Epoch 979/1000\n",
      "202/202 [==============================] - 0s 135us/step - loss: 7.8789e-05 - accuracy: 1.0000 - val_loss: 0.2934 - val_accuracy: 0.9804\n",
      "Epoch 980/1000\n",
      "202/202 [==============================] - 0s 141us/step - loss: 7.9061e-05 - accuracy: 1.0000 - val_loss: 0.2911 - val_accuracy: 0.9804\n",
      "Epoch 981/1000\n",
      "202/202 [==============================] - 0s 131us/step - loss: 7.6882e-05 - accuracy: 1.0000 - val_loss: 0.2921 - val_accuracy: 0.9804\n",
      "Epoch 982/1000\n",
      "202/202 [==============================] - 0s 96us/step - loss: 7.6786e-05 - accuracy: 1.0000 - val_loss: 0.2926 - val_accuracy: 0.9804\n",
      "Epoch 983/1000\n",
      "202/202 [==============================] - 0s 117us/step - loss: 7.9497e-05 - accuracy: 1.0000 - val_loss: 0.2929 - val_accuracy: 0.9804\n",
      "Epoch 984/1000\n",
      "202/202 [==============================] - 0s 109us/step - loss: 7.6578e-05 - accuracy: 1.0000 - val_loss: 0.2918 - val_accuracy: 0.9804\n",
      "Epoch 985/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202/202 [==============================] - 0s 88us/step - loss: 7.7932e-05 - accuracy: 1.0000 - val_loss: 0.2889 - val_accuracy: 0.9804\n",
      "Epoch 986/1000\n",
      "202/202 [==============================] - 0s 86us/step - loss: 7.6759e-05 - accuracy: 1.0000 - val_loss: 0.2912 - val_accuracy: 0.9804\n",
      "Epoch 987/1000\n",
      "202/202 [==============================] - 0s 109us/step - loss: 7.6244e-05 - accuracy: 1.0000 - val_loss: 0.2917 - val_accuracy: 0.9804\n",
      "Epoch 988/1000\n",
      "202/202 [==============================] - 0s 88us/step - loss: 7.6305e-05 - accuracy: 1.0000 - val_loss: 0.2968 - val_accuracy: 0.9804\n",
      "Epoch 989/1000\n",
      "202/202 [==============================] - 0s 95us/step - loss: 7.8149e-05 - accuracy: 1.0000 - val_loss: 0.2945 - val_accuracy: 0.9804\n",
      "Epoch 990/1000\n",
      "202/202 [==============================] - 0s 90us/step - loss: 7.5456e-05 - accuracy: 1.0000 - val_loss: 0.2917 - val_accuracy: 0.9804\n",
      "Epoch 991/1000\n",
      "202/202 [==============================] - 0s 99us/step - loss: 7.4779e-05 - accuracy: 1.0000 - val_loss: 0.2948 - val_accuracy: 0.9804\n",
      "Epoch 992/1000\n",
      "202/202 [==============================] - 0s 84us/step - loss: 7.4893e-05 - accuracy: 1.0000 - val_loss: 0.2917 - val_accuracy: 0.9804\n",
      "Epoch 993/1000\n",
      "202/202 [==============================] - 0s 92us/step - loss: 7.3506e-05 - accuracy: 1.0000 - val_loss: 0.2878 - val_accuracy: 0.9804\n",
      "Epoch 994/1000\n",
      "202/202 [==============================] - 0s 90us/step - loss: 7.5563e-05 - accuracy: 1.0000 - val_loss: 0.2897 - val_accuracy: 0.9804\n",
      "Epoch 995/1000\n",
      "202/202 [==============================] - 0s 88us/step - loss: 7.2578e-05 - accuracy: 1.0000 - val_loss: 0.2951 - val_accuracy: 0.9804\n",
      "Epoch 996/1000\n",
      "202/202 [==============================] - 0s 85us/step - loss: 7.4209e-05 - accuracy: 1.0000 - val_loss: 0.2960 - val_accuracy: 0.9804\n",
      "Epoch 997/1000\n",
      "202/202 [==============================] - 0s 106us/step - loss: 7.1989e-05 - accuracy: 1.0000 - val_loss: 0.2907 - val_accuracy: 0.9804\n",
      "Epoch 998/1000\n",
      "202/202 [==============================] - 0s 89us/step - loss: 7.2730e-05 - accuracy: 1.0000 - val_loss: 0.2900 - val_accuracy: 0.9804\n",
      "Epoch 999/1000\n",
      "202/202 [==============================] - 0s 101us/step - loss: 7.3661e-05 - accuracy: 1.0000 - val_loss: 0.2918 - val_accuracy: 0.9804\n",
      "Epoch 1000/1000\n",
      "202/202 [==============================] - 0s 88us/step - loss: 7.2412e-05 - accuracy: 1.0000 - val_loss: 0.2872 - val_accuracy: 0.9804\n"
     ]
    }
   ],
   "source": [
    "#Training process\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 162us/step\n",
      "test_acc:  0.9736841917037964 0.25200567276854263\n"
     ]
    }
   ],
   "source": [
    "#getting accuracy and loss data\n",
    "test_loss, test_acc = model.evaluate(X_test,y_test)\n",
    "print('test_acc: ',test_acc,test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting Accuracy and loss graphics\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('aides_classification_final.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 100.00%\n",
      "accuracy: 100.00%\n",
      "accuracy: 100.00%\n",
      "accuracy: 100.00%\n",
      "accuracy: 100.00%\n",
      "accuracy: 100.00%\n",
      "accuracy: 100.00%\n",
      "accuracy: 100.00%\n",
      "accuracy: 100.00%\n",
      "accuracy: 100.00%\n",
      "100.00% (+/- 0.00%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score,StratifiedKFold\n",
    "import numpy\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# label_encoder = LabelEncoder()\n",
    "# yyr = label_encoder.fit_transform(yr)\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=55)\n",
    "cvscores = []\n",
    "for train, test in kfold.split(X, y):\n",
    "  # create model\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(64, activation='relu', input_dim=13))\n",
    "    model.add(layers.Dense(32, activation='relu'))\n",
    "    model.add(layers.Dense(16, activation='relu'))\n",
    "    model.add(layers.Dense(2, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train, epochs=150, batch_size=10, verbose=0)\n",
    "    # evaluate the model\n",
    "    scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    cvscores.append(scores[1] * 100)\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (numpy.mean(cvscores), numpy.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 2. Prediction (Validation Using Recorded Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'filename' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-1099e26fbc8d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"aides_classification_6.h5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0msongname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf'./Aides_testData/{filename}'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msongname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmono\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmfcc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmfcc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_mfcc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m13\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfmax\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'filename' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model (\"aides_classification_6.h5\")\n",
    "songname = f'./Aides_testData/{filename}'\n",
    "y, sr = librosa.load(songname, mono=True, duration=30)\n",
    "mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13, fmax=1000)\n",
    "mean = np.std(mfcc, axis=1)\n",
    "mean = np.array(mean.reshape(1,-1))\n",
    "X_ujii = mean\n",
    "a=model.predict(X_ujii)\n",
    "#Give percentage of the results\n",
    "predicts1 = {\"aegypti\":round((a[0][1]*100),2),\n",
    "             \"others\":round((a[0][0]*100),2)}\n",
    "print('PREDICTION RESULT:')\n",
    "for key, value in sorted(predicts1.items(), key=lambda item: item[1], reverse=True):\n",
    "    print(f\"{key}\\t: {value} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moezeus/anaconda3/lib/python3.7/site-packages/librosa/core/audio.py:161: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n"
     ]
    }
   ],
   "source": [
    "y, sr = librosa.load('anekoik.m4a', mono=True, duration=30)\n",
    "mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13,fmin=400, fmax=10000)\n",
    "mfcc_delta = librosa.feature.delta(mfcc)\n",
    "mfcc_delta2 = librosa.feature.delta(mfcc, order=2)\n",
    "mean = np.mean(mfcc, axis=1)\n",
    "mean_delta = np.mean(mfcc_delta, axis=1)\n",
    "mean_delta2 = np.mean(mfcc_delta2, axis=1)\n",
    "# mean_delta = np.array(mean_delta.reshape(1,-1))\n",
    "# mean = np.array(mean.reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13,)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(mean_delta.T).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "df = pd.DataFrame(mean)\n",
    "df1 = pd.DataFrame(mean_delta)\n",
    "df2 = pd.DataFrame(mean_delta2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.append(df1, ignore_index=True)\n",
    "df = df.append(df2, ignore_index=True)\n",
    "df = df.T\n",
    "XY = np.array(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "n_components=7 must be between 0 and min(n_samples, n_features)=1 with svd_solver='full'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-111-511584d9692b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# pca = PCA(n_components=7)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# dataset = pca.fit(X_uji)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtesss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# tesss = pca.transform(XY)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    342\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mitself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m         \"\"\"\n\u001b[0;32m--> 344\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;31m# Call different fits for either full or truncated SVD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_svd_solver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'full'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_full\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_svd_solver\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'arpack'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'randomized'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_truncated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_svd_solver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36m_fit_full\u001b[0;34m(self, X, n_components)\u001b[0m\n\u001b[1;32m    433\u001b[0m                              \u001b[0;34m\"min(n_samples, n_features)=%r with \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m                              \u001b[0;34m\"svd_solver='full'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m                              % (n_components, min(n_samples, n_features)))\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mn_components\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIntegral\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: n_components=7 must be between 0 and min(n_samples, n_features)=1 with svd_solver='full'"
     ]
    }
   ],
   "source": [
    "# pca = PCA(n_components=7)\n",
    "# dataset = pca.fit(X_uji)\n",
    "tesss = pca.fit(XY)\n",
    "# tesss = pca.transform(XY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 39)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
